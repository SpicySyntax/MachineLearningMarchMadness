{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #dataframes\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np # n-dim object support\n",
    "# do ploting inline instead of in a separate window\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school = pd.read_csv(\"../Scraper/school_records.csv\")\n",
    "df_ps_game = pd.read_csv(\"../Scraper/post_season_game_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3478, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_school.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_name</th>\n",
       "      <th>fg_pg</th>\n",
       "      <th>ft_pg</th>\n",
       "      <th>three_pt_pg</th>\n",
       "      <th>orb_pg</th>\n",
       "      <th>drb_pg</th>\n",
       "      <th>ast_pg</th>\n",
       "      <th>stl_pg</th>\n",
       "      <th>blk_pg</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_pg</th>\n",
       "      <th>pt_pg</th>\n",
       "      <th>opnt_pt_pg</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>three_p_pct</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>wl_pct</th>\n",
       "      <th>conf_wl_pct</th>\n",
       "      <th>srs</th>\n",
       "      <th>sos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>20.387097</td>\n",
       "      <td>10.741935</td>\n",
       "      <td>5.677419</td>\n",
       "      <td>7.096774</td>\n",
       "      <td>27.222685</td>\n",
       "      <td>12.548387</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>17.645161</td>\n",
       "      <td>57.193548</td>\n",
       "      <td>63.129032</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Akron</td>\n",
       "      <td>25.057143</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>13.342857</td>\n",
       "      <td>35.875918</td>\n",
       "      <td>13.514286</td>\n",
       "      <td>6.085714</td>\n",
       "      <td>3.257143</td>\n",
       "      <td>...</td>\n",
       "      <td>19.485714</td>\n",
       "      <td>70.628571</td>\n",
       "      <td>65.514286</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>22.185185</td>\n",
       "      <td>17.481481</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.925926</td>\n",
       "      <td>36.669410</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>5.296296</td>\n",
       "      <td>...</td>\n",
       "      <td>20.370370</td>\n",
       "      <td>65.851852</td>\n",
       "      <td>69.666667</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-20.19</td>\n",
       "      <td>-13.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>22.441176</td>\n",
       "      <td>16.852941</td>\n",
       "      <td>5.205882</td>\n",
       "      <td>12.352941</td>\n",
       "      <td>36.342561</td>\n",
       "      <td>11.470588</td>\n",
       "      <td>6.558824</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>...</td>\n",
       "      <td>17.970588</td>\n",
       "      <td>66.941176</td>\n",
       "      <td>60.382353</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>9.46</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Alabama State</td>\n",
       "      <td>21.516129</td>\n",
       "      <td>15.290323</td>\n",
       "      <td>6.129032</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>35.099896</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>7.354839</td>\n",
       "      <td>4.161290</td>\n",
       "      <td>...</td>\n",
       "      <td>20.451613</td>\n",
       "      <td>64.451613</td>\n",
       "      <td>65.903226</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-14.41</td>\n",
       "      <td>-12.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           team_name      fg_pg      ft_pg  three_pt_pg     orb_pg  \\\n",
       "0  2010           Air Force  20.387097  10.741935     5.677419   7.096774   \n",
       "1  2010               Akron  25.057143  13.800000     6.714286  13.342857   \n",
       "2  2010         Alabama A&M  22.185185  17.481481     4.000000  13.925926   \n",
       "3  2010  Alabama-Birmingham  22.441176  16.852941     5.205882  12.352941   \n",
       "4  2010       Alabama State  21.516129  15.290323     6.129032  12.903226   \n",
       "\n",
       "      drb_pg     ast_pg    stl_pg    blk_pg  ...      pf_pg      pt_pg  \\\n",
       "0  27.222685  12.548387  5.000000  1.645161  ...  17.645161  57.193548   \n",
       "1  35.875918  13.514286  6.085714  3.257143  ...  19.485714  70.628571   \n",
       "2  36.669410  10.666667  9.222222  5.296296  ...  20.370370  65.851852   \n",
       "3  36.342561  11.470588  6.558824  2.676471  ...  17.970588  66.941176   \n",
       "4  35.099896  12.903226  7.354839  4.161290  ...  20.451613  64.451613   \n",
       "\n",
       "   opnt_pt_pg  fg_pct  three_p_pct  ft_pct  wl_pct  conf_wl_pct    srs    sos  \n",
       "0   63.129032   0.443        0.313   0.635   0.323     0.062500  -4.90   3.13  \n",
       "1   65.514286   0.433        0.339   0.657   0.686     0.750000   2.82  -1.50  \n",
       "2   69.666667   0.382        0.291   0.635   0.407     0.444444 -20.19 -13.71  \n",
       "3   60.382353   0.422        0.311   0.694   0.735     0.687500   9.46   2.90  \n",
       "4   65.903226   0.404        0.324   0.641   0.516     0.666667 -14.41 -12.02  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_school.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_1_name</th>\n",
       "      <th>team_1_score</th>\n",
       "      <th>team_1_seed</th>\n",
       "      <th>team_2_name</th>\n",
       "      <th>team_2_score</th>\n",
       "      <th>team_2_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>UTSA</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>Princeton</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   team_1_name  team_1_score  team_1_seed    team_2_name  team_2_score  \\\n",
       "0  2011          UTSA            46           16     Ohio State            75   \n",
       "1  2011  George Mason            61            8      Villanova            57   \n",
       "2  2011       Clemson            76           12  West Virginia            84   \n",
       "3  2011     Princeton            57           13       Kentucky            59   \n",
       "4  2011     Marquette            66           11         Xavier            55   \n",
       "\n",
       "   team_2_seed  \n",
       "0            1  \n",
       "1            9  \n",
       "2            5  \n",
       "3            4  \n",
       "4            6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_school.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_team_name(team_name):\n",
    "    #Apply hard-coded corrections to team names\n",
    "    team_name_dict = {'Colorado-Colorado Springs':'Colorado',\n",
    "                     'Colorado College': 'Colorado',\n",
    "                     'UNC':'North Carolina',\n",
    "                     'UConn':'Connecticut',\n",
    "                     'LIU-Brooklyn':'Long Island University',\n",
    "                     'UTSA':'Texas-San Antonio',\n",
    "                     'Pitt':'Pittsburgh',\n",
    "                     'BYU':'Brigham Young',\n",
    "                     \"St. Peter's\": \"Saint Peter's\",\n",
    "                     'VCU':'Virginia Commonwealth',\n",
    "                     'Southern Miss':'Southern Mississippi',\n",
    "                     'Detroit': 'Detroit Mercy',\n",
    "                     'UNLV':'Nevada-Las Vegas',\n",
    "                     'Ole Miss':'Mississippi',\n",
    "                     \"St. Joseph's\":\"Saint Joseph's\",\n",
    "                     'UCSB':'UC-Santa Barbara',\n",
    "                     'SMU': 'Southern Methodist',\n",
    "                     'USC':'South Carolina',\n",
    "                     'LSU':'Louisiana State',\n",
    "                     'UMass':'Massachusetts',\n",
    "                     'ETSU':'East Tennessee State'}\n",
    "    # TODO: for V2 add more corrections to the team_name_dict\n",
    "    if(team_name in team_name_dict):\n",
    "        return team_name_dict[team_name]\n",
    "    return team_name\n",
    "def get_school_stats(year, team_name):\n",
    "    return df_school[(df_school['year'] == year) & (df_school['team_name'] == team_name)]\n",
    "def get_vals(t_stats_list, key):\n",
    "    ret = []\n",
    "    for t_stat in t_stats_list:\n",
    "        ret.append(t_stat[key].squeeze())\n",
    "    return ret\n",
    "def get_team_stats_dict_with_t1_win(t1_stats, t2_stats, t1_wins):\n",
    "    return {'team_name_1':get_vals(t1_stats,'team_name'),'fg_pg_1':get_vals(t1_stats,'fg_pg'),'ft_pg_1':get_vals(t1_stats,'ft_pg'),\n",
    "            'three_pt_pg_1':get_vals(t1_stats,'three_pt_pg'),'orb_pg_1':get_vals(t1_stats,'orb_pg'),'drb_pg_1':get_vals(t1_stats,'drb_pg'),\n",
    "            'ast_pg_1':get_vals(t1_stats,'ast_pg'),'stl_pg_1':get_vals(t1_stats,'stl_pg'),'blk_pg_1':get_vals(t1_stats,'blk_pg'),\n",
    "            'tov_pg_1':get_vals(t1_stats,'tov_pg'),'pf_pg_1':get_vals(t1_stats,'pf_pg'), 'pt_pg_1':get_vals(t1_stats,'pt_pg'),\n",
    "            'opnt_pt_pg_1':get_vals(t1_stats,'opnt_pt_pg'),'fg_pct_1':get_vals(t1_stats,'fg_pct'),'three_p_pct_1':get_vals(t1_stats,'three_p_pct'),\n",
    "            'ft_pct_1':get_vals(t1_stats,'ft_pct'),'wl_pct_1':get_vals(t1_stats,'wl_pct'),'conf_wl_pct_1':get_vals(t1_stats,'conf_wl_pct'),\n",
    "            'srs_1':get_vals(t1_stats,'srs'),'sos_1':get_vals(t1_stats,'sos'),\n",
    "            'team_name_2':get_vals(t2_stats,'team_name'),'fg_pg_2':get_vals(t2_stats,'fg_pg'),'ft_pg_2':get_vals(t2_stats,'ft_pg'),\n",
    "            'three_pt_pg_2':get_vals(t2_stats,'three_pt_pg'),'orb_pg_2':get_vals(t2_stats,'orb_pg'),'drb_pg_2':get_vals(t2_stats,'drb_pg'),\n",
    "            'ast_pg_2':get_vals(t2_stats,'ast_pg'),'stl_pg_2':get_vals(t2_stats,'stl_pg'),'blk_pg_2':get_vals(t2_stats,'blk_pg'),\n",
    "            'tov_pg_2':get_vals(t2_stats,'tov_pg'),'pf_pg_2':get_vals(t2_stats,'pf_pg'), 'pt_pg_2':get_vals(t2_stats,'pt_pg'),\n",
    "            'opnt_pt_pg_2':get_vals(t2_stats,'opnt_pt_pg'),'fg_pct_2':get_vals(t2_stats,'fg_pct'),'three_p_pct_2':get_vals(t2_stats,'three_p_pct'),\n",
    "            'ft_pct_2':get_vals(t2_stats,'ft_pct'),'wl_pct_2':get_vals(t2_stats,'wl_pct'),'conf_wl_pct_2':get_vals(t2_stats,'conf_wl_pct'),\n",
    "            'srs_2':get_vals(t2_stats,'srs'),'sos_2':get_vals(t2_stats,'sos'),\n",
    "            't1_win':t1_wins}\n",
    "def get_team_stats_dict(t1_stats, t2_stats):\n",
    "    return {'team_name_1':get_vals(t1_stats,'team_name'),'fg_pg_1':get_vals(t1_stats,'fg_pg'),'ft_pg_1':get_vals(t1_stats,'ft_pg'),\n",
    "            'three_pt_pg_1':get_vals(t1_stats,'three_pt_pg'),'orb_pg_1':get_vals(t1_stats,'orb_pg'),'drb_pg_1':get_vals(t1_stats,'drb_pg'),\n",
    "            'ast_pg_1':get_vals(t1_stats,'ast_pg'),'stl_pg_1':get_vals(t1_stats,'stl_pg'),'blk_pg_1':get_vals(t1_stats,'blk_pg'),\n",
    "            'tov_pg_1':get_vals(t1_stats,'tov_pg'),'pf_pg_1':get_vals(t1_stats,'pf_pg'), 'pt_pg_1':get_vals(t1_stats,'pt_pg'),\n",
    "            'opnt_pt_pg_1':get_vals(t1_stats,'opnt_pt_pg'),'fg_pct_1':get_vals(t1_stats,'fg_pct'),'three_p_pct_1':get_vals(t1_stats,'three_p_pct'),\n",
    "            'ft_pct_1':get_vals(t1_stats,'ft_pct'),'wl_pct_1':get_vals(t1_stats,'wl_pct'),'conf_wl_pct_1':get_vals(t1_stats,'conf_wl_pct'),\n",
    "            'srs_1':get_vals(t1_stats,'srs'),'sos_1':get_vals(t1_stats,'sos'),\n",
    "            'team_name_2':get_vals(t2_stats,'team_name'),'fg_pg_2':get_vals(t2_stats,'fg_pg'),'ft_pg_2':get_vals(t2_stats,'ft_pg'),\n",
    "            'three_pt_pg_2':get_vals(t2_stats,'three_pt_pg'),'orb_pg_2':get_vals(t2_stats,'orb_pg'),'drb_pg_2':get_vals(t2_stats,'drb_pg'),\n",
    "            'ast_pg_2':get_vals(t2_stats,'ast_pg'),'stl_pg_2':get_vals(t2_stats,'stl_pg'),'blk_pg_2':get_vals(t2_stats,'blk_pg'),\n",
    "            'tov_pg_2':get_vals(t2_stats,'tov_pg'),'pf_pg_2':get_vals(t2_stats,'pf_pg'), 'pt_pg_2':get_vals(t2_stats,'pt_pg'),\n",
    "            'opnt_pt_pg_2':get_vals(t2_stats,'opnt_pt_pg'),'fg_pct_2':get_vals(t2_stats,'fg_pct'),'three_p_pct_2':get_vals(t2_stats,'three_p_pct'),\n",
    "            'ft_pct_2':get_vals(t2_stats,'ft_pct'),'wl_pct_2':get_vals(t2_stats,'wl_pct'),'conf_wl_pct_2':get_vals(t2_stats,'conf_wl_pct'),\n",
    "            'srs_2':get_vals(t2_stats,'srs'),'sos_2':get_vals(t2_stats,'sos')}\n",
    "def get_team_stats_dict_ps(t1_stats, t2_stats, t1_seeds, t2_seeds):\n",
    "    return {'team_name_1':get_vals(t1_stats,'team_name'),'fg_pg_1':get_vals(t1_stats,'fg_pg'),'ft_pg_1':get_vals(t1_stats,'ft_pg'),\n",
    "            'three_pt_pg_1':get_vals(t1_stats,'three_pt_pg'),'orb_pg_1':get_vals(t1_stats,'orb_pg'),'drb_pg_1':get_vals(t1_stats,'drb_pg'),\n",
    "            'ast_pg_1':get_vals(t1_stats,'ast_pg'),'stl_pg_1':get_vals(t1_stats,'stl_pg'),'blk_pg_1':get_vals(t1_stats,'blk_pg'),\n",
    "            'tov_pg_1':get_vals(t1_stats,'tov_pg'),'pf_pg_1':get_vals(t1_stats,'pf_pg'), 'pt_pg_1':get_vals(t1_stats,'pt_pg'),\n",
    "            'opnt_pt_pg_1':get_vals(t1_stats,'opnt_pt_pg'),'fg_pct_1':get_vals(t1_stats,'fg_pct'),'three_p_pct_1':get_vals(t1_stats,'three_p_pct'),\n",
    "            'ft_pct_1':get_vals(t1_stats,'ft_pct'),'wl_pct_1':get_vals(t1_stats,'wl_pct'),'conf_wl_pct_1':get_vals(t1_stats,'conf_wl_pct'),\n",
    "            'srs_1':get_vals(t1_stats,'srs'),'sos_1':get_vals(t1_stats,'sos'),\n",
    "            'team_name_2':get_vals(t2_stats,'team_name'),'fg_pg_2':get_vals(t2_stats,'fg_pg'),'ft_pg_2':get_vals(t2_stats,'ft_pg'),\n",
    "            'three_pt_pg_2':get_vals(t2_stats,'three_pt_pg'),'orb_pg_2':get_vals(t2_stats,'orb_pg'),'drb_pg_2':get_vals(t2_stats,'drb_pg'),\n",
    "            'ast_pg_2':get_vals(t2_stats,'ast_pg'),'stl_pg_2':get_vals(t2_stats,'stl_pg'),'blk_pg_2':get_vals(t2_stats,'blk_pg'),\n",
    "            'tov_pg_2':get_vals(t2_stats,'tov_pg'),'pf_pg_2':get_vals(t2_stats,'pf_pg'), 'pt_pg_2':get_vals(t2_stats,'pt_pg'),\n",
    "            'opnt_pt_pg_2':get_vals(t2_stats,'opnt_pt_pg'),'fg_pct_2':get_vals(t2_stats,'fg_pct'),'three_p_pct_2':get_vals(t2_stats,'three_p_pct'),\n",
    "            'ft_pct_2':get_vals(t2_stats,'ft_pct'),'wl_pct_2':get_vals(t2_stats,'wl_pct'),'conf_wl_pct_2':get_vals(t2_stats,'conf_wl_pct'),\n",
    "            'srs_2':get_vals(t2_stats,'srs'),'sos_2':get_vals(t2_stats,'sos'), 'team_1_seed':t1_seeds,\n",
    "            'team_2_seed':t2_seeds}\n",
    "def create_team_stats_df_w_t1_win(indeces_w_stats, t1_stats_list, t2_stats_list,t1_wins):\n",
    "    # Adds column for wether team 1 wins or not\n",
    "    # Assumes all lists are of the same length\n",
    "    return pd.DataFrame(get_team_stats_dict_with_t1_win(t1_stats_list, t2_stats_list,t1_wins), index = indeces_w_stats)\n",
    "def create_team_stats_df(indeces_w_stats, t1_stats_list, t2_stats_list):\n",
    "    # Assumes all lists are of the same length\n",
    "    return pd.DataFrame(get_team_stats_dict(t1_stats_list, t2_stats_list), index = indeces_w_stats)\n",
    "def create_team_stats_df_ps(indeces_w_stats, t1_stats_list, t2_stats_list, t1_seeds, t2_seeds):\n",
    "    # Only uses post season stats => inclu\n",
    "    # Assumes all lists are of the same length\n",
    "    return pd.DataFrame(get_team_stats_dict_ps(t1_stats_list, t2_stats_list, t1_seeds, t2_seeds), index = indeces_w_stats)\n",
    "def get_team_stats_df(game_df, should_print=False):\n",
    "    indeces_w_stats = []\n",
    "    t1_stats_list = []\n",
    "    t2_stats_list = []\n",
    "    t1_wins_list = []\n",
    "    for index, row in game_df.iterrows():\n",
    "        year = row['year']\n",
    "        team_1 = row['team_1_name']\n",
    "        team_2 = row['team_2_name']\n",
    "        team_1_score = row['team_1_score']\n",
    "        team_2_score = row['team_2_score']\n",
    "        t1_stats = get_school_stats(year, resolve_team_name(team_1))\n",
    "        t2_stats = get_school_stats(year, resolve_team_name(team_2))\n",
    "\n",
    "        if(len(t1_stats) > 0 and len(t2_stats) > 0):  \n",
    "            indeces_w_stats.append(index)\n",
    "            t1_stats_list.append(t1_stats)\n",
    "            t2_stats_list.append(t2_stats)\n",
    "            t1_wins_list.append(team_1_score > team_2_score)\n",
    "        else:         \n",
    "            if(should_print):\n",
    "                print(year)\n",
    "                if(len(t1_stats) < 1):\n",
    "                    print(team_1)\n",
    "                if(len(t2_stats) < 1):\n",
    "                    print(team_2)\n",
    "            \n",
    "    print(len(indeces_w_stats))\n",
    "    team_stats_df = create_team_stats_df_w_t1_win(indeces_w_stats, t1_stats_list, t2_stats_list, t1_wins_list)\n",
    "    return team_stats_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "UNC Greensboro\n",
      "2018\n",
      "Penn\n",
      "2018\n",
      "NC State\n",
      "2018\n",
      "TCU\n",
      "2018\n",
      "UMBC\n",
      "2018\n",
      "UMBC\n",
      "498\n"
     ]
    }
   ],
   "source": [
    "ps_team_stats_df = get_team_stats_df(df_ps_game, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_game_w_team_stats = pd.concat([df_ps_game, ps_team_stats_df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_1_name</th>\n",
       "      <th>team_1_score</th>\n",
       "      <th>team_1_seed</th>\n",
       "      <th>team_2_name</th>\n",
       "      <th>team_2_score</th>\n",
       "      <th>team_2_seed</th>\n",
       "      <th>team_name_1</th>\n",
       "      <th>fg_pg_1</th>\n",
       "      <th>ft_pg_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pt_pg_2</th>\n",
       "      <th>opnt_pt_pg_2</th>\n",
       "      <th>fg_pct_2</th>\n",
       "      <th>three_p_pct_2</th>\n",
       "      <th>ft_pct_2</th>\n",
       "      <th>wl_pct_2</th>\n",
       "      <th>conf_wl_pct_2</th>\n",
       "      <th>srs_2</th>\n",
       "      <th>sos_2</th>\n",
       "      <th>t1_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>UTSA</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>Texas-San Antonio</td>\n",
       "      <td>23.588235</td>\n",
       "      <td>16.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>77.135135</td>\n",
       "      <td>59.675676</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>25.84</td>\n",
       "      <td>8.38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>25.764706</td>\n",
       "      <td>14.558824</td>\n",
       "      <td>...</td>\n",
       "      <td>72.242424</td>\n",
       "      <td>65.424242</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>15.05</td>\n",
       "      <td>8.23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>23.823529</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>69.787879</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>16.15</td>\n",
       "      <td>11.03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   team_1_name  team_1_score  team_1_seed    team_2_name  team_2_score  \\\n",
       "0  2011          UTSA            46           16     Ohio State            75   \n",
       "1  2011  George Mason            61            8      Villanova            57   \n",
       "2  2011       Clemson            76           12  West Virginia            84   \n",
       "\n",
       "   team_2_seed        team_name_1    fg_pg_1    ft_pg_1  ...    pt_pg_2  \\\n",
       "0            1  Texas-San Antonio  23.588235  16.058824  ...  77.135135   \n",
       "1            9       George Mason  25.764706  14.558824  ...  72.242424   \n",
       "2            5            Clemson  23.823529  14.500000  ...  69.787879   \n",
       "\n",
       "   opnt_pt_pg_2  fg_pct_2  three_p_pct_2  ft_pct_2  wl_pct_2  conf_wl_pct_2  \\\n",
       "0     59.675676     0.494          0.423     0.701     0.919       0.888889   \n",
       "1     65.424242     0.438          0.348     0.757     0.636       0.500000   \n",
       "2     64.666667     0.429          0.337     0.711     0.636       0.611111   \n",
       "\n",
       "   srs_2  sos_2  t1_win  \n",
       "0  25.84   8.38   False  \n",
       "1  15.05   8.23    True  \n",
       "2  16.15  11.03   False  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_game_w_team_stats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 48)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_game_w_team_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check team 1 winning true/false ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True cases: 259 (52.01%)\n",
      "Number of False cases: 239 (47.99%)\n"
     ]
    }
   ],
   "source": [
    "t1_win_map = {True:1, False:0}\n",
    "ps_game_w_team_stats['t1_win'] = ps_game_w_team_stats['t1_win'].map(t1_win_map)\n",
    "num_true = len(ps_game_w_team_stats.loc[ps_game_w_team_stats['t1_win'] == True])\n",
    "num_false = len(ps_game_w_team_stats.loc[ps_game_w_team_stats['t1_win'] == False])\n",
    "print(\"Number of True cases: {0} ({1:2.2f}%)\".format(num_true, (num_true/(num_true+num_false))*100))\n",
    "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_false, (num_false/(num_true+num_false))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "ps_feature_col_names = ['team_1_seed', 'team_2_seed','fg_pg_1','ft_pg_1',\n",
    "            'three_pt_pg_1','orb_pg_1','drb_pg_1',\n",
    "            'ast_pg_1','stl_pg_1','blk_pg_1',\n",
    "            'tov_pg_1','pf_pg_1', 'pt_pg_1',\n",
    "            'opnt_pt_pg_1','fg_pct_1','three_p_pct_1',\n",
    "            'ft_pct_1','wl_pct_1','conf_wl_pct_1',\n",
    "            'srs_1','sos_1',\n",
    "            'fg_pg_2','ft_pg_2',\n",
    "            'three_pt_pg_2','orb_pg_2','drb_pg_2',\n",
    "            'ast_pg_2','stl_pg_2','blk_pg_2',\n",
    "            'tov_pg_2','pf_pg_2', 'pt_pg_2',\n",
    "            'opnt_pt_pg_2','fg_pct_2','three_p_pct_2',\n",
    "            'ft_pct_2','wl_pct_2','conf_wl_pct_2',\n",
    "            'srs_2','sos_2'\n",
    "            ]\n",
    "ps_predict_class_names = ['t1_win']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(data, col_names):\n",
    "    scaled_features = {}\n",
    "    for col_name in col_names:\n",
    "        mean, std = data[col_name].values.mean(), data[col_name].values.std()\n",
    "        scaled_features[col_name] = [mean, std]\n",
    "        data.loc[:, col_name] = (data[col_name].values - mean)/std\n",
    "    return scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "scale_features(ps_game_w_team_stats, ps_feature_col_names)\n",
    "ps_x = ps_game_w_team_stats[ps_feature_col_names].values\n",
    "ps_y = ps_game_w_team_stats[ps_predict_class_names].values\n",
    "print(type(ps_x))\n",
    "split_test_size = 0.2\n",
    "ps_x_train, ps_x_test, ps_y_train, ps_y_test = sklearn.model_selection.train_test_split(ps_x, ps_y, test_size=split_test_size, random_state=42)\n",
    "split_valid_size = 0.25\n",
    "ps_x_train, ps_x_val, ps_y_train, ps_y_val = sklearn.model_selection.train_test_split(ps_x_train, ps_y_train, test_size=split_valid_size, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.84% in training set\n",
      "20.08% in test set\n",
      "20.08% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(ps_x_train)/len(ps_game_w_team_stats.index))*100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(ps_x_test)/len(ps_game_w_team_stats.index))*100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(ps_x_val)/len(ps_game_w_team_stats.index))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.impute\n",
    "\n",
    "#Impute with mean all 0 readings\n",
    "fill_0 = sklearn.impute.SimpleImputer(missing_values=0, strategy=\"mean\")\n",
    "\n",
    "ps_x_train = fill_0.fit_transform(ps_x_train)\n",
    "ps_x_test = fill_0.fit_transform(ps_x_test)\n",
    "ps_x_val = fill_0.fit_transform(ps_x_val)\n",
    "# TODO : impute incorrect negative values such anything other than (SOS and SRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(ps_x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.8784,  1.0063, -0.2218, -0.5439, -0.0466, -0.0116, -0.0256,  0.8330,\n",
      "         -0.4402,  0.0745, -0.9502,  0.2407, -0.3926, -0.7599, -0.5942,  0.1154,\n",
      "          0.0996,  0.2147,  0.4424,  0.6467,  0.5807, -0.9921, -0.1811,  1.0188,\n",
      "         -0.2898, -1.1671,  0.1403,  1.3164, -0.5491, -0.3529,  0.5443, -0.5698,\n",
      "          0.3269, -1.2511,  0.2916,  0.0995, -0.5304, -0.4341, -1.0058, -0.5689],\n",
      "        [-1.0949, -1.2675,  0.4426,  0.1311, -1.3617,  0.1437, -0.3711,  0.1399,\n",
      "          0.3467, -0.7537, -0.1964, -0.6685,  0.0373, -1.1872,  0.6528, -1.0004,\n",
      "         -0.0763,  0.5408,  0.0234,  1.2681,  0.6608,  0.5074, -0.8850, -0.5554,\n",
      "          0.7176, -1.3220,  0.5173,  2.0758,  2.4618, -0.9123, -1.0215, -0.0759,\n",
      "         -0.8781,  0.2606, -0.5362, -0.3867,  1.7935,  1.6683,  0.8729,  0.3712],\n",
      "        [-1.0949,  1.9159,  0.1650, -0.2320,  0.3129,  1.1011,  1.2250,  1.0161,\n",
      "          0.5051,  1.3189, -0.0982, -0.8924,  0.1357, -1.7539, -0.2502,  0.0410,\n",
      "         -0.6041,  1.4103,  1.2805,  0.9066, -0.5722,  0.4909, -1.7036,  1.6242,\n",
      "         -1.3863, -0.5943, -0.5369,  0.6210,  0.4773, -0.3885,  0.3391,  0.1859,\n",
      "          0.4666,  0.0316,  0.8828, -1.2735, -0.6578, -0.4341, -1.8375, -2.1742]]), tensor([[0.],\n",
      "        [1.],\n",
      "        [1.]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "dropout = 0.5\n",
    "model = nn.Sequential(nn.Linear(40, 30),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(dropout),\n",
    "                     nn.Linear(30, 30),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(dropout),\n",
    "                     nn.Linear(30, 10),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(dropout),\n",
    "                     nn.Linear(10, 1),\n",
    "                     nn.Sigmoid())\n",
    "trainset = TensorDataset(torch.from_numpy(ps_x_train).float(), torch.from_numpy(ps_y_train).float())\n",
    "trainloader = DataLoader(trainset, batch_size=3, shuffle=True)\n",
    "testset = TensorDataset(torch.from_numpy(ps_x_test).float(), torch.from_numpy(ps_y_test).float())\n",
    "testloader = DataLoader(testset, batch_size=3, shuffle=True)\n",
    "valset = TensorDataset(torch.from_numpy(ps_x_val).float(), torch.from_numpy(ps_y_val).float())\n",
    "valloader = DataLoader(valset, batch_size=3, shuffle=True)\n",
    "print(next(iter(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print ('Using CUDA: {}'.format(use_cuda))\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, train_loader, val_loader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    # TODO: fix target tensors always zero for some reason\n",
    "    valid_loss_min = np.Inf \n",
    "    print_loss_count = 40\n",
    "    cuda_refresh_count = 5\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        train_load_iter = iter(train_loader)\n",
    "        for i in range(len(train_loader)):\n",
    "            data, target = next(train_load_iter)\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()    \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            train_loss = train_loss + ((1 / (i + 1)) * (loss.data - train_loss))\n",
    "\n",
    "        model.eval()\n",
    "        val_load_iter = iter(val_loader)\n",
    "        for i in range(len(val_loader)):\n",
    "            data, target = next(val_load_iter)\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (i + 1)) * (loss.data - valid_loss))\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        ## save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.694864 \tValidation Loss: 0.694825\n",
      "Validation loss decreased (inf --> 0.694825).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.696691 \tValidation Loss: 0.696323\n",
      "Epoch: 3 \tTraining Loss: 0.695185 \tValidation Loss: 0.694812\n",
      "Validation loss decreased (0.694825 --> 0.694812).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.691325 \tValidation Loss: 0.693610\n",
      "Validation loss decreased (0.694812 --> 0.693610).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.692976 \tValidation Loss: 0.690144\n",
      "Validation loss decreased (0.693610 --> 0.690144).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.688731 \tValidation Loss: 0.691535\n",
      "Epoch: 7 \tTraining Loss: 0.688258 \tValidation Loss: 0.690295\n",
      "Epoch: 8 \tTraining Loss: 0.687805 \tValidation Loss: 0.686997\n",
      "Validation loss decreased (0.690144 --> 0.686997).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.683537 \tValidation Loss: 0.685116\n",
      "Validation loss decreased (0.686997 --> 0.685116).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.685419 \tValidation Loss: 0.683004\n",
      "Validation loss decreased (0.685116 --> 0.683004).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.682377 \tValidation Loss: 0.682092\n",
      "Validation loss decreased (0.683004 --> 0.682092).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.680837 \tValidation Loss: 0.678526\n",
      "Validation loss decreased (0.682092 --> 0.678526).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.676083 \tValidation Loss: 0.674568\n",
      "Validation loss decreased (0.678526 --> 0.674568).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.678657 \tValidation Loss: 0.671102\n",
      "Validation loss decreased (0.674568 --> 0.671102).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.673471 \tValidation Loss: 0.666360\n",
      "Validation loss decreased (0.671102 --> 0.666360).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.664279 \tValidation Loss: 0.654983\n",
      "Validation loss decreased (0.666360 --> 0.654983).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.653500 \tValidation Loss: 0.650414\n",
      "Validation loss decreased (0.654983 --> 0.650414).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.648446 \tValidation Loss: 0.637875\n",
      "Validation loss decreased (0.650414 --> 0.637875).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.647718 \tValidation Loss: 0.625387\n",
      "Validation loss decreased (0.637875 --> 0.625387).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.632273 \tValidation Loss: 0.616087\n",
      "Validation loss decreased (0.625387 --> 0.616087).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.614532 \tValidation Loss: 0.590361\n",
      "Validation loss decreased (0.616087 --> 0.590361).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.645777 \tValidation Loss: 0.589386\n",
      "Validation loss decreased (0.590361 --> 0.589386).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.613138 \tValidation Loss: 0.581088\n",
      "Validation loss decreased (0.589386 --> 0.581088).  Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 0.632960 \tValidation Loss: 0.576776\n",
      "Validation loss decreased (0.581088 --> 0.576776).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.568563 \tValidation Loss: 0.559710\n",
      "Validation loss decreased (0.576776 --> 0.559710).  Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 0.596154 \tValidation Loss: 0.547529\n",
      "Validation loss decreased (0.559710 --> 0.547529).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.634444 \tValidation Loss: 0.563393\n",
      "Epoch: 28 \tTraining Loss: 0.571287 \tValidation Loss: 0.534673\n",
      "Validation loss decreased (0.547529 --> 0.534673).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.572109 \tValidation Loss: 0.531772\n",
      "Validation loss decreased (0.534673 --> 0.531772).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.575277 \tValidation Loss: 0.520052\n",
      "Validation loss decreased (0.531772 --> 0.520052).  Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 0.581940 \tValidation Loss: 0.517354\n",
      "Validation loss decreased (0.520052 --> 0.517354).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.565380 \tValidation Loss: 0.525107\n",
      "Epoch: 33 \tTraining Loss: 0.562666 \tValidation Loss: 0.503664\n",
      "Validation loss decreased (0.517354 --> 0.503664).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.569915 \tValidation Loss: 0.522599\n",
      "Epoch: 35 \tTraining Loss: 0.564398 \tValidation Loss: 0.501514\n",
      "Validation loss decreased (0.503664 --> 0.501514).  Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 0.561805 \tValidation Loss: 0.517136\n",
      "Epoch: 37 \tTraining Loss: 0.557156 \tValidation Loss: 0.505873\n",
      "Epoch: 38 \tTraining Loss: 0.523640 \tValidation Loss: 0.503141\n",
      "Epoch: 39 \tTraining Loss: 0.525634 \tValidation Loss: 0.505589\n",
      "Epoch: 40 \tTraining Loss: 0.547158 \tValidation Loss: 0.497945\n",
      "Validation loss decreased (0.501514 --> 0.497945).  Saving model ...\n",
      "Epoch: 41 \tTraining Loss: 0.548932 \tValidation Loss: 0.492792\n",
      "Validation loss decreased (0.497945 --> 0.492792).  Saving model ...\n",
      "Epoch: 42 \tTraining Loss: 0.522000 \tValidation Loss: 0.494392\n",
      "Epoch: 43 \tTraining Loss: 0.542861 \tValidation Loss: 0.500381\n",
      "Epoch: 44 \tTraining Loss: 0.540749 \tValidation Loss: 0.516122\n",
      "Epoch: 45 \tTraining Loss: 0.503319 \tValidation Loss: 0.504152\n",
      "Epoch: 46 \tTraining Loss: 0.511225 \tValidation Loss: 0.514924\n",
      "Epoch: 47 \tTraining Loss: 0.501096 \tValidation Loss: 0.496340\n",
      "Epoch: 48 \tTraining Loss: 0.511040 \tValidation Loss: 0.496230\n",
      "Epoch: 49 \tTraining Loss: 0.488765 \tValidation Loss: 0.495770\n",
      "Epoch: 50 \tTraining Loss: 0.525440 \tValidation Loss: 0.494094\n",
      "Epoch: 51 \tTraining Loss: 0.487873 \tValidation Loss: 0.503074\n",
      "Epoch: 52 \tTraining Loss: 0.554080 \tValidation Loss: 0.510982\n",
      "Epoch: 53 \tTraining Loss: 0.517131 \tValidation Loss: 0.511467\n",
      "Epoch: 54 \tTraining Loss: 0.496009 \tValidation Loss: 0.507228\n",
      "Epoch: 55 \tTraining Loss: 0.461000 \tValidation Loss: 0.508418\n",
      "Epoch: 56 \tTraining Loss: 0.486404 \tValidation Loss: 0.511818\n",
      "Epoch: 57 \tTraining Loss: 0.469548 \tValidation Loss: 0.517491\n",
      "Epoch: 58 \tTraining Loss: 0.453434 \tValidation Loss: 0.526666\n",
      "Epoch: 59 \tTraining Loss: 0.483633 \tValidation Loss: 0.520910\n",
      "Epoch: 60 \tTraining Loss: 0.453313 \tValidation Loss: 0.623559\n",
      "Epoch: 61 \tTraining Loss: 0.483561 \tValidation Loss: 0.545430\n",
      "Epoch: 62 \tTraining Loss: 0.477319 \tValidation Loss: 0.565025\n",
      "Epoch: 63 \tTraining Loss: 0.479644 \tValidation Loss: 0.560557\n",
      "Epoch: 64 \tTraining Loss: 0.422517 \tValidation Loss: 0.543348\n",
      "Epoch: 65 \tTraining Loss: 0.417063 \tValidation Loss: 0.546891\n",
      "Epoch: 66 \tTraining Loss: 0.503932 \tValidation Loss: 0.545046\n",
      "Epoch: 67 \tTraining Loss: 0.429057 \tValidation Loss: 0.571580\n",
      "Epoch: 68 \tTraining Loss: 0.425819 \tValidation Loss: 0.550791\n",
      "Epoch: 69 \tTraining Loss: 0.460737 \tValidation Loss: 0.582278\n",
      "Epoch: 70 \tTraining Loss: 0.439360 \tValidation Loss: 0.599284\n",
      "Epoch: 71 \tTraining Loss: 0.426110 \tValidation Loss: 0.595666\n",
      "Epoch: 72 \tTraining Loss: 0.458604 \tValidation Loss: 0.599297\n",
      "Epoch: 73 \tTraining Loss: 0.400374 \tValidation Loss: 0.603901\n",
      "Epoch: 74 \tTraining Loss: 0.491895 \tValidation Loss: 0.574981\n",
      "Epoch: 75 \tTraining Loss: 0.421313 \tValidation Loss: 0.585740\n",
      "Epoch: 76 \tTraining Loss: 0.431959 \tValidation Loss: 0.594422\n",
      "Epoch: 77 \tTraining Loss: 0.415294 \tValidation Loss: 0.583580\n",
      "Epoch: 78 \tTraining Loss: 0.360533 \tValidation Loss: 0.588604\n",
      "Epoch: 79 \tTraining Loss: 0.415221 \tValidation Loss: 0.585962\n",
      "Epoch: 80 \tTraining Loss: 0.371174 \tValidation Loss: 0.599254\n",
      "Epoch: 81 \tTraining Loss: 0.417177 \tValidation Loss: 0.614038\n",
      "Epoch: 82 \tTraining Loss: 0.416782 \tValidation Loss: 0.589995\n",
      "Epoch: 83 \tTraining Loss: 0.429629 \tValidation Loss: 0.584554\n",
      "Epoch: 84 \tTraining Loss: 0.413479 \tValidation Loss: 0.626366\n",
      "Epoch: 85 \tTraining Loss: 0.366681 \tValidation Loss: 0.720228\n",
      "Epoch: 86 \tTraining Loss: 0.388051 \tValidation Loss: 0.683193\n",
      "Epoch: 87 \tTraining Loss: 0.369617 \tValidation Loss: 0.672884\n",
      "Epoch: 88 \tTraining Loss: 0.431249 \tValidation Loss: 0.684748\n",
      "Epoch: 89 \tTraining Loss: 0.399656 \tValidation Loss: 0.612336\n",
      "Epoch: 90 \tTraining Loss: 0.411735 \tValidation Loss: 0.618341\n",
      "Epoch: 91 \tTraining Loss: 0.393737 \tValidation Loss: 0.625625\n",
      "Epoch: 92 \tTraining Loss: 0.388890 \tValidation Loss: 0.624487\n",
      "Epoch: 93 \tTraining Loss: 0.364898 \tValidation Loss: 0.684813\n",
      "Epoch: 94 \tTraining Loss: 0.402093 \tValidation Loss: 0.711021\n",
      "Epoch: 95 \tTraining Loss: 0.365965 \tValidation Loss: 0.712742\n",
      "Epoch: 96 \tTraining Loss: 0.379647 \tValidation Loss: 0.684626\n",
      "Epoch: 97 \tTraining Loss: 0.339923 \tValidation Loss: 0.640916\n",
      "Epoch: 98 \tTraining Loss: 0.339737 \tValidation Loss: 0.693967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99 \tTraining Loss: 0.360873 \tValidation Loss: 0.686525\n",
      "Epoch: 100 \tTraining Loss: 0.408990 \tValidation Loss: 0.696803\n",
      "Epoch: 101 \tTraining Loss: 0.324089 \tValidation Loss: 0.725288\n",
      "Epoch: 102 \tTraining Loss: 0.388927 \tValidation Loss: 0.655730\n",
      "Epoch: 103 \tTraining Loss: 0.398857 \tValidation Loss: 0.646196\n",
      "Epoch: 104 \tTraining Loss: 0.355109 \tValidation Loss: 0.700692\n",
      "Epoch: 105 \tTraining Loss: 0.368273 \tValidation Loss: 0.710731\n",
      "Epoch: 106 \tTraining Loss: 0.354027 \tValidation Loss: 0.724133\n",
      "Epoch: 107 \tTraining Loss: 0.345299 \tValidation Loss: 0.742154\n",
      "Epoch: 108 \tTraining Loss: 0.383961 \tValidation Loss: 0.739921\n",
      "Epoch: 109 \tTraining Loss: 0.342146 \tValidation Loss: 0.743813\n",
      "Epoch: 110 \tTraining Loss: 0.330957 \tValidation Loss: 0.763999\n",
      "Epoch: 111 \tTraining Loss: 0.286655 \tValidation Loss: 0.735209\n",
      "Epoch: 112 \tTraining Loss: 0.351697 \tValidation Loss: 0.669973\n",
      "Epoch: 113 \tTraining Loss: 0.341263 \tValidation Loss: 0.721137\n",
      "Epoch: 114 \tTraining Loss: 0.287619 \tValidation Loss: 0.735816\n",
      "Epoch: 115 \tTraining Loss: 0.349460 \tValidation Loss: 0.739964\n",
      "Epoch: 116 \tTraining Loss: 0.309310 \tValidation Loss: 0.773100\n",
      "Epoch: 117 \tTraining Loss: 0.381989 \tValidation Loss: 0.810525\n",
      "Epoch: 118 \tTraining Loss: 0.311124 \tValidation Loss: 0.825471\n",
      "Epoch: 119 \tTraining Loss: 0.373896 \tValidation Loss: 0.774274\n",
      "Epoch: 120 \tTraining Loss: 0.286517 \tValidation Loss: 0.818730\n"
     ]
    }
   ],
   "source": [
    "model = train(120, trainloader, valloader, model, optimizer, criterion,\n",
    "                      use_cuda, 'model_nn1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, criterion, use_cuda, num_classes = 2):\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    model.eval()\n",
    "    load_iter = iter(loader)\n",
    "    for i in range(len(loader)):\n",
    "        data, target = next(load_iter)\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (i + 1)) * (loss.data - test_loss))\n",
    "        # compare predictions to true label\n",
    "        for j, tensor in enumerate(output):\n",
    "            if (tensor.item() > .5 and target[j] == 1) or (tensor.item() <= .5 and target[j] == 0):\n",
    "                correct += 1\n",
    "        total += data.size(0)\n",
    "       \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.832023\n",
      "\n",
      "\n",
      "Test Accuracy: 70% (70/100)\n"
     ]
    }
   ],
   "source": [
    "test(testloader, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup This years bracket regions\n",
    "# TODO: automate this with the data received from the scraper\n",
    "school_names_south = [\n",
    "    # south region\n",
    "    ('Virginia', 1),('Maryland-Baltimore County', 16),\n",
    "    ('Creighton', 8), ('Kansas State', 9),\n",
    "    ('Kentucky',5), ('Davidson', 12),\n",
    "    ('Arizona',4), ('Buffalo', 13),\n",
    "    ('Miami (FL)', 6), ('Loyola (IL)', 11),\n",
    "    ('Tennessee',3), ('Wright State',14),\n",
    "    ('Nevada',7),('Texas',10),\n",
    "    ('Cincinnati',2), ('Georgia State',15)\n",
    "    ]\n",
    "school_names_west = [\n",
    "    # west region\n",
    "    ('Xavier', 1),('North Carolina Central',16), #or 'Texas Southern',\n",
    "    ('Missouri', 8),('Florida State', 9),\n",
    "    ('Ohio State',5), ('South Dakota State', 12),\n",
    "    ('Gonzaga',4), ('North Carolina-Greensboro',13),\n",
    "    ('Houston',6),('San Diego State',11),\n",
    "    ('Michigan', 3),('Montana', 14),\n",
    "    ('Texas A&M',7),('Providence',10),\n",
    "    ('North Carolina',2),('Lipscomb',15)\n",
    "    ]\n",
    "school_names_east = [\n",
    "    # east region\n",
    "    ('Villanova',1),('Long Island University',16), # or 'Radford',\n",
    "    ('Virginia Tech',8), ('Alabama',9),\n",
    "    ('West Virginia',5), ('Murray State',12),\n",
    "    ('Wichita State',4), ('Marshall',13),\n",
    "    ('Florida',6), ('St. Bonaventure',11), # or 'UCLA',\n",
    "    ('Texas Tech',3), ('Stephen F. Austin',14),\n",
    "    ('Arkansas',7), ('Butler',10),\n",
    "    ('Purdue', 2), ('Cal State Fullerton',15)\n",
    "    ]\n",
    "school_names_midwest = [\n",
    "    # mid-west region\n",
    "    ('Kansas', 1), ('Pennsylvania',16),\n",
    "    ('Seton Hall', 8), ('North Carolina State',9),\n",
    "    ('Clemson', 5), ('New Mexico State',12),\n",
    "    ('Auburn',4), ('College of Charleston',13),\n",
    "    ('Texas Christian',6), ('Arizona State',11), # or 'Syracuse',\n",
    "    ('Michigan State',3), ('Bucknell',14),\n",
    "    ('Rhode Island',7), ('Oklahoma',10),\n",
    "    ('Duke', 2), ('Iona' ,15) \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Methods to add evaluating the predicted winners of matchups and subbrackets (A region or Final Four)\n",
    "    To change the predictive model used, just change the model handed to \"evaluate_winner(schools,sub_bracket_name, model)\"\n",
    "    found later in the notebook\n",
    "'''\n",
    "def get_matchups_stats(schools, post_season):    \n",
    "    \n",
    "    i = 0 \n",
    "    t1_stats = []\n",
    "    t2_stats = []\n",
    "    t1_seeds = []\n",
    "    t2_seeds = []\n",
    "    if(not is_power_of_two(len(schools))):\n",
    "        print('ERROR: invalid number of school names')\n",
    "        return False\n",
    "    while i < len(schools):\n",
    "        t1_name, t1_seed = schools[i]\n",
    "        t2_name, t2_seed = schools[i + 1]\n",
    "        t1_seeds.append(t1_seed)\n",
    "        t2_seeds.append(t2_seed)\n",
    "        #print(t1_name, t2_name\n",
    "        t1_stats.append(get_school_stats(2018, t1_name))\n",
    "        t2_stats.append(get_school_stats(2018, t2_name))\n",
    "        i = i + 2\n",
    "    if(post_season):\n",
    "        matchup_stats = create_team_stats_df_ps(range(0,int(len(schools)/2)), t1_stats, t2_stats, t1_seeds, t2_seeds)\n",
    "    else:\n",
    "        matchup_stats = create_team_stats_df(range(0,int(len(schools)/2)), t1_stats, t2_stats)\n",
    "    return matchup_stats\n",
    "def is_power_of_two(num):\n",
    "    return ((num & (num - 1)) == 0) and num != 0\n",
    "def get_matchup_winners(matchup_stats, schools, model, post_season, use_cuda):\n",
    "\n",
    "    x_tourney = matchup_stats[ps_feature_col_names].values\n",
    "    x_tourney = torch.from_numpy(x_tourney).float()\n",
    "    # print(x_tourney)\n",
    "    if use_cuda:\n",
    "        x_tourney = x_tourney.cuda()\n",
    "    y_tourney = model(x_tourney)\n",
    "    #print(y_tourney)\n",
    "    i = 0\n",
    "    winners = []\n",
    "    for y_val in y_tourney:\n",
    "        t1_name, t1_seed = schools[i]\n",
    "        t2_name, t2_seed = schools[i + 1]\n",
    "        t1_won = y_val.item() > .5\n",
    "        print(t1_name,t1_seed,' vs. ', t2_name,t2_seed,'(team 1 won=', t1_won,')')\n",
    "        if(t1_won):\n",
    "            winners.append((t1_name,t1_seed))\n",
    "        else:\n",
    "            winners.append((t2_name, t2_seed))\n",
    "        i = i + 2\n",
    "    return winners\n",
    "def evaluate_winner(schools,sub_bracket_name, model, use_cuda):        \n",
    "    remaining_teams = schools\n",
    "    i = 1\n",
    "    while(len(remaining_teams) > 1):\n",
    "        #Add a random factor\n",
    "        rand = random.randrange(0,1)\n",
    "        post_season_stats = True\n",
    "        print(\"---\",sub_bracket_name,\" round \",i,\"---\")\n",
    "        matchup_stats = get_matchups_stats(remaining_teams, post_season_stats)\n",
    "        remaining_teams = get_matchup_winners(matchup_stats,remaining_teams, model, post_season_stats, use_cuda)\n",
    "        i = i + 1\n",
    "    winner = remaining_teams[0]\n",
    "    print('Winner of ',sub_bracket_name,':',winner)\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- South  round  1 ---\n",
      "Virginia 1  vs.  Maryland-Baltimore County 16 (team 1 won= True )\n",
      "Creighton 8  vs.  Kansas State 9 (team 1 won= False )\n",
      "Kentucky 5  vs.  Davidson 12 (team 1 won= True )\n",
      "Arizona 4  vs.  Buffalo 13 (team 1 won= True )\n",
      "Miami (FL) 6  vs.  Loyola (IL) 11 (team 1 won= True )\n",
      "Tennessee 3  vs.  Wright State 14 (team 1 won= True )\n",
      "Nevada 7  vs.  Texas 10 (team 1 won= False )\n",
      "Cincinnati 2  vs.  Georgia State 15 (team 1 won= True )\n",
      "--- South  round  2 ---\n",
      "Virginia 1  vs.  Kansas State 9 (team 1 won= True )\n",
      "Kentucky 5  vs.  Arizona 4 (team 1 won= True )\n",
      "Miami (FL) 6  vs.  Tennessee 3 (team 1 won= False )\n",
      "Texas 10  vs.  Cincinnati 2 (team 1 won= True )\n",
      "--- South  round  3 ---\n",
      "Virginia 1  vs.  Kentucky 5 (team 1 won= True )\n",
      "Tennessee 3  vs.  Texas 10 (team 1 won= False )\n",
      "--- South  round  4 ---\n",
      "Virginia 1  vs.  Texas 10 (team 1 won= True )\n",
      "Winner of  South : ('Virginia', 1)\n",
      "--- West  round  1 ---\n",
      "Xavier 1  vs.  North Carolina Central 16 (team 1 won= True )\n",
      "Missouri 8  vs.  Florida State 9 (team 1 won= False )\n",
      "Ohio State 5  vs.  South Dakota State 12 (team 1 won= True )\n",
      "Gonzaga 4  vs.  North Carolina-Greensboro 13 (team 1 won= True )\n",
      "Houston 6  vs.  San Diego State 11 (team 1 won= True )\n",
      "Michigan 3  vs.  Montana 14 (team 1 won= True )\n",
      "Texas A&M 7  vs.  Providence 10 (team 1 won= False )\n",
      "North Carolina 2  vs.  Lipscomb 15 (team 1 won= True )\n",
      "--- West  round  2 ---\n",
      "Xavier 1  vs.  Florida State 9 (team 1 won= False )\n",
      "Ohio State 5  vs.  Gonzaga 4 (team 1 won= True )\n",
      "Houston 6  vs.  Michigan 3 (team 1 won= False )\n",
      "Providence 10  vs.  North Carolina 2 (team 1 won= False )\n",
      "--- West  round  3 ---\n",
      "Florida State 9  vs.  Ohio State 5 (team 1 won= False )\n",
      "Michigan 3  vs.  North Carolina 2 (team 1 won= False )\n",
      "--- West  round  4 ---\n",
      "Ohio State 5  vs.  North Carolina 2 (team 1 won= False )\n",
      "Winner of  West : ('North Carolina', 2)\n",
      "--- East  round  1 ---\n",
      "Villanova 1  vs.  Long Island University 16 (team 1 won= True )\n",
      "Virginia Tech 8  vs.  Alabama 9 (team 1 won= False )\n",
      "West Virginia 5  vs.  Murray State 12 (team 1 won= True )\n",
      "Wichita State 4  vs.  Marshall 13 (team 1 won= True )\n",
      "Florida 6  vs.  St. Bonaventure 11 (team 1 won= True )\n",
      "Texas Tech 3  vs.  Stephen F. Austin 14 (team 1 won= True )\n",
      "Arkansas 7  vs.  Butler 10 (team 1 won= False )\n",
      "Purdue 2  vs.  Cal State Fullerton 15 (team 1 won= True )\n",
      "--- East  round  2 ---\n",
      "Villanova 1  vs.  Alabama 9 (team 1 won= False )\n",
      "West Virginia 5  vs.  Wichita State 4 (team 1 won= True )\n",
      "Florida 6  vs.  Texas Tech 3 (team 1 won= False )\n",
      "Butler 10  vs.  Purdue 2 (team 1 won= False )\n",
      "--- East  round  3 ---\n",
      "Alabama 9  vs.  West Virginia 5 (team 1 won= False )\n",
      "Texas Tech 3  vs.  Purdue 2 (team 1 won= False )\n",
      "--- East  round  4 ---\n",
      "West Virginia 5  vs.  Purdue 2 (team 1 won= False )\n",
      "Winner of  East : ('Purdue', 2)\n",
      "--- MidWest  round  1 ---\n",
      "Kansas 1  vs.  Pennsylvania 16 (team 1 won= True )\n",
      "Seton Hall 8  vs.  North Carolina State 9 (team 1 won= True )\n",
      "Clemson 5  vs.  New Mexico State 12 (team 1 won= True )\n",
      "Auburn 4  vs.  College of Charleston 13 (team 1 won= True )\n",
      "Texas Christian 6  vs.  Arizona State 11 (team 1 won= False )\n",
      "Michigan State 3  vs.  Bucknell 14 (team 1 won= True )\n",
      "Rhode Island 7  vs.  Oklahoma 10 (team 1 won= False )\n",
      "Duke 2  vs.  Iona 15 (team 1 won= True )\n",
      "--- MidWest  round  2 ---\n",
      "Kansas 1  vs.  Seton Hall 8 (team 1 won= False )\n",
      "Clemson 5  vs.  Auburn 4 (team 1 won= False )\n",
      "Arizona State 11  vs.  Michigan State 3 (team 1 won= False )\n",
      "Oklahoma 10  vs.  Duke 2 (team 1 won= False )\n",
      "--- MidWest  round  3 ---\n",
      "Seton Hall 8  vs.  Auburn 4 (team 1 won= False )\n",
      "Michigan State 3  vs.  Duke 2 (team 1 won= False )\n",
      "--- MidWest  round  4 ---\n",
      "Auburn 4  vs.  Duke 2 (team 1 won= False )\n",
      "Winner of  MidWest : ('Duke', 2)\n"
     ]
    }
   ],
   "source": [
    "# Get predicted final four\n",
    "\n",
    "final_four = [evaluate_winner(school_names_south, \"South\",model, use_cuda), evaluate_winner(school_names_west,\"West\",model, use_cuda),\n",
    "              evaluate_winner(school_names_east, \"East\", model, use_cuda), evaluate_winner(school_names_midwest, \"MidWest\",model, use_cuda)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Virginia', 1), ('North Carolina', 2), ('Purdue', 2), ('Duke', 2)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FinalFour  round  1 ---\n",
      "Virginia 1  vs.  North Carolina 2 (team 1 won= True )\n",
      "Purdue 2  vs.  Duke 2 (team 1 won= False )\n",
      "--- FinalFour  round  2 ---\n",
      "Virginia 1  vs.  Duke 2 (team 1 won= False )\n",
      "Winner of  FinalFour : ('Duke', 2)\n"
     ]
    }
   ],
   "source": [
    "champ = evaluate_winner(final_four, \"FinalFour\", model, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
