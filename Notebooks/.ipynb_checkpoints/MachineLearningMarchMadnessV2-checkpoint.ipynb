{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #dataframes\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np # n-dim object support\n",
    "# do ploting inline instead of in a separate window\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school = pd.read_csv(\"../Scraper/school_records.csv\")\n",
    "df_ps_game = pd.read_csv(\"../Scraper/post_season_game_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3478, 21)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_school.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 7)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_name</th>\n",
       "      <th>fg_pg</th>\n",
       "      <th>ft_pg</th>\n",
       "      <th>three_pt_pg</th>\n",
       "      <th>orb_pg</th>\n",
       "      <th>drb_pg</th>\n",
       "      <th>ast_pg</th>\n",
       "      <th>stl_pg</th>\n",
       "      <th>blk_pg</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_pg</th>\n",
       "      <th>pt_pg</th>\n",
       "      <th>opnt_pt_pg</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>three_p_pct</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>wl_pct</th>\n",
       "      <th>conf_wl_pct</th>\n",
       "      <th>srs</th>\n",
       "      <th>sos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>20.387097</td>\n",
       "      <td>10.741935</td>\n",
       "      <td>5.677419</td>\n",
       "      <td>7.096774</td>\n",
       "      <td>27.222685</td>\n",
       "      <td>12.548387</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>17.645161</td>\n",
       "      <td>57.193548</td>\n",
       "      <td>63.129032</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Akron</td>\n",
       "      <td>25.057143</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>13.342857</td>\n",
       "      <td>35.875918</td>\n",
       "      <td>13.514286</td>\n",
       "      <td>6.085714</td>\n",
       "      <td>3.257143</td>\n",
       "      <td>...</td>\n",
       "      <td>19.485714</td>\n",
       "      <td>70.628571</td>\n",
       "      <td>65.514286</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>22.185185</td>\n",
       "      <td>17.481481</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.925926</td>\n",
       "      <td>36.669410</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>5.296296</td>\n",
       "      <td>...</td>\n",
       "      <td>20.370370</td>\n",
       "      <td>65.851852</td>\n",
       "      <td>69.666667</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-20.19</td>\n",
       "      <td>-13.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>22.441176</td>\n",
       "      <td>16.852941</td>\n",
       "      <td>5.205882</td>\n",
       "      <td>12.352941</td>\n",
       "      <td>36.342561</td>\n",
       "      <td>11.470588</td>\n",
       "      <td>6.558824</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>...</td>\n",
       "      <td>17.970588</td>\n",
       "      <td>66.941176</td>\n",
       "      <td>60.382353</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>9.46</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Alabama State</td>\n",
       "      <td>21.516129</td>\n",
       "      <td>15.290323</td>\n",
       "      <td>6.129032</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>35.099896</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>7.354839</td>\n",
       "      <td>4.161290</td>\n",
       "      <td>...</td>\n",
       "      <td>20.451613</td>\n",
       "      <td>64.451613</td>\n",
       "      <td>65.903226</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-14.41</td>\n",
       "      <td>-12.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           team_name      fg_pg      ft_pg  three_pt_pg     orb_pg  \\\n",
       "0  2010           Air Force  20.387097  10.741935     5.677419   7.096774   \n",
       "1  2010               Akron  25.057143  13.800000     6.714286  13.342857   \n",
       "2  2010         Alabama A&M  22.185185  17.481481     4.000000  13.925926   \n",
       "3  2010  Alabama-Birmingham  22.441176  16.852941     5.205882  12.352941   \n",
       "4  2010       Alabama State  21.516129  15.290323     6.129032  12.903226   \n",
       "\n",
       "      drb_pg     ast_pg    stl_pg    blk_pg  ...      pf_pg      pt_pg  \\\n",
       "0  27.222685  12.548387  5.000000  1.645161  ...  17.645161  57.193548   \n",
       "1  35.875918  13.514286  6.085714  3.257143  ...  19.485714  70.628571   \n",
       "2  36.669410  10.666667  9.222222  5.296296  ...  20.370370  65.851852   \n",
       "3  36.342561  11.470588  6.558824  2.676471  ...  17.970588  66.941176   \n",
       "4  35.099896  12.903226  7.354839  4.161290  ...  20.451613  64.451613   \n",
       "\n",
       "   opnt_pt_pg  fg_pct  three_p_pct  ft_pct  wl_pct  conf_wl_pct    srs    sos  \n",
       "0   63.129032   0.443        0.313   0.635   0.323     0.062500  -4.90   3.13  \n",
       "1   65.514286   0.433        0.339   0.657   0.686     0.750000   2.82  -1.50  \n",
       "2   69.666667   0.382        0.291   0.635   0.407     0.444444 -20.19 -13.71  \n",
       "3   60.382353   0.422        0.311   0.694   0.735     0.687500   9.46   2.90  \n",
       "4   65.903226   0.404        0.324   0.641   0.516     0.666667 -14.41 -12.02  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_school.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_1_name</th>\n",
       "      <th>team_1_score</th>\n",
       "      <th>team_1_seed</th>\n",
       "      <th>team_2_name</th>\n",
       "      <th>team_2_score</th>\n",
       "      <th>team_2_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>UTSA</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>Princeton</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   team_1_name  team_1_score  team_1_seed    team_2_name  team_2_score  \\\n",
       "0  2011          UTSA            46           16     Ohio State            75   \n",
       "1  2011  George Mason            61            8      Villanova            57   \n",
       "2  2011       Clemson            76           12  West Virginia            84   \n",
       "3  2011     Princeton            57           13       Kentucky            59   \n",
       "4  2011     Marquette            66           11         Xavier            55   \n",
       "\n",
       "   team_2_seed  \n",
       "0            1  \n",
       "1            9  \n",
       "2            5  \n",
       "3            4  \n",
       "4            6  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_school.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "UNC Greensboro\n",
      "2018\n",
      "Penn\n",
      "2018\n",
      "NC State\n",
      "2018\n",
      "TCU\n",
      "2018\n",
      "UMBC\n",
      "2018\n",
      "UMBC\n",
      "498\n"
     ]
    }
   ],
   "source": [
    "import shared\n",
    "ps_team_stats_df = shared.get_team_stats_df(df_school, df_ps_game, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_game_w_team_stats = pd.concat([df_ps_game, ps_team_stats_df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_1_name</th>\n",
       "      <th>team_1_score</th>\n",
       "      <th>team_1_seed</th>\n",
       "      <th>team_2_name</th>\n",
       "      <th>team_2_score</th>\n",
       "      <th>team_2_seed</th>\n",
       "      <th>team_name_1</th>\n",
       "      <th>fg_pg_1</th>\n",
       "      <th>ft_pg_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pt_pg_2</th>\n",
       "      <th>opnt_pt_pg_2</th>\n",
       "      <th>fg_pct_2</th>\n",
       "      <th>three_p_pct_2</th>\n",
       "      <th>ft_pct_2</th>\n",
       "      <th>wl_pct_2</th>\n",
       "      <th>conf_wl_pct_2</th>\n",
       "      <th>srs_2</th>\n",
       "      <th>sos_2</th>\n",
       "      <th>t1_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>UTSA</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>Texas-San Antonio</td>\n",
       "      <td>23.588235</td>\n",
       "      <td>16.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>77.135135</td>\n",
       "      <td>59.675676</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>25.84</td>\n",
       "      <td>8.38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>25.764706</td>\n",
       "      <td>14.558824</td>\n",
       "      <td>...</td>\n",
       "      <td>72.242424</td>\n",
       "      <td>65.424242</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>15.05</td>\n",
       "      <td>8.23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>23.823529</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>69.787879</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>16.15</td>\n",
       "      <td>11.03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   team_1_name  team_1_score  team_1_seed    team_2_name  team_2_score  \\\n",
       "0  2011          UTSA            46           16     Ohio State            75   \n",
       "1  2011  George Mason            61            8      Villanova            57   \n",
       "2  2011       Clemson            76           12  West Virginia            84   \n",
       "\n",
       "   team_2_seed        team_name_1    fg_pg_1    ft_pg_1  ...    pt_pg_2  \\\n",
       "0            1  Texas-San Antonio  23.588235  16.058824  ...  77.135135   \n",
       "1            9       George Mason  25.764706  14.558824  ...  72.242424   \n",
       "2            5            Clemson  23.823529  14.500000  ...  69.787879   \n",
       "\n",
       "   opnt_pt_pg_2  fg_pct_2  three_p_pct_2  ft_pct_2  wl_pct_2  conf_wl_pct_2  \\\n",
       "0     59.675676     0.494          0.423     0.701     0.919       0.888889   \n",
       "1     65.424242     0.438          0.348     0.757     0.636       0.500000   \n",
       "2     64.666667     0.429          0.337     0.711     0.636       0.611111   \n",
       "\n",
       "   srs_2  sos_2  t1_win  \n",
       "0  25.84   8.38   False  \n",
       "1  15.05   8.23    True  \n",
       "2  16.15  11.03   False  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_game_w_team_stats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 48)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_game_w_team_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check team 1 winning true/false ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True cases: 259 (52.01%)\n",
      "Number of False cases: 239 (47.99%)\n"
     ]
    }
   ],
   "source": [
    "t1_win_map = {True:1, False:0}\n",
    "ps_game_w_team_stats['t1_win'] = ps_game_w_team_stats['t1_win'].map(t1_win_map)\n",
    "num_true = len(ps_game_w_team_stats.loc[ps_game_w_team_stats['t1_win'] == True])\n",
    "num_false = len(ps_game_w_team_stats.loc[ps_game_w_team_stats['t1_win'] == False])\n",
    "print(\"Number of True cases: {0} ({1:2.2f}%)\".format(num_true, (num_true/(num_true+num_false))*100))\n",
    "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_false, (num_false/(num_true+num_false))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(data, col_names):\n",
    "    scaled_features = {}\n",
    "    for col_name in col_names:\n",
    "        mean, std = data[col_name].values.mean(), data[col_name].values.std()\n",
    "        scaled_features[col_name] = [mean, std]\n",
    "        data.loc[:, col_name] = (data[col_name].values - mean)/std\n",
    "    return scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "scale_features(ps_game_w_team_stats, shared.ps_feature_col_names)\n",
    "ps_x = ps_game_w_team_stats[shared.ps_feature_col_names].values\n",
    "ps_y = ps_game_w_team_stats[shared.ps_predict_class_names].values\n",
    "print(type(ps_x))\n",
    "split_test_size = 0.2\n",
    "ps_x_train, ps_x_test, ps_y_train, ps_y_test = sklearn.model_selection.train_test_split(ps_x, ps_y, test_size=split_test_size, random_state=42)\n",
    "split_valid_size = 0.25\n",
    "ps_x_train, ps_x_val, ps_y_train, ps_y_val = sklearn.model_selection.train_test_split(ps_x_train, ps_y_train, test_size=split_valid_size, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.84% in training set\n",
      "20.08% in test set\n",
      "20.08% in validation set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(ps_x_train)/len(ps_game_w_team_stats.index))*100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(ps_x_test)/len(ps_game_w_team_stats.index))*100))\n",
    "print(\"{0:0.2f}% in validation set\".format((len(ps_x_val)/len(ps_game_w_team_stats.index))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.impute\n",
    "\n",
    "#Impute with mean all 0 readings\n",
    "fill_0 = sklearn.impute.SimpleImputer(missing_values=0, strategy=\"mean\")\n",
    "\n",
    "ps_x_train = fill_0.fit_transform(ps_x_train)\n",
    "ps_x_test = fill_0.fit_transform(ps_x_test)\n",
    "ps_x_val = fill_0.fit_transform(ps_x_val)\n",
    "# TODO : impute incorrect negative values such anything other than (SOS and SRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(ps_x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.4455, -0.5854, -0.7817, -0.1089,  1.1281, -0.6374, -1.5091, -0.8737,\n",
      "         -0.6460, -0.0548,  0.7647, -0.6922, -0.3708, -0.1041,  0.0078,  1.0080,\n",
      "         -0.3695, -0.5570, -0.7100,  0.1525,  0.4437, -2.0261, -1.7072,  0.6152,\n",
      "         -0.8838, -1.6546, -1.3754, -1.2598, -0.5491, -2.0678, -1.7282, -2.0663,\n",
      "         -2.4929, -1.6634,  0.2128,  0.7861, -0.2970, -0.4341,  0.5618,  0.4199],\n",
      "        [ 0.2038, -1.2675,  0.0250, -1.5822,  0.4891,  0.6727,  0.5780, -0.3787,\n",
      "         -0.0064, -0.4825, -0.4735, -0.6040, -0.4226, -0.6495, -0.2502, -0.0706,\n",
      "         -1.9823, -0.1657, -0.3957,  0.6521,  0.7303,  0.3150, -0.0663,  1.1373,\n",
      "         -1.4253, -0.7257, -0.1685,  0.4998, -0.9683, -0.4478, -1.6826,  0.5318,\n",
      "         -0.5333,  1.5433,  0.2522,  2.2449,  1.4751,  0.8274,  1.2738,  0.6505],\n",
      "        [-0.0126, -1.0401, -1.1461, -1.1543,  0.5829,  0.3614, -1.7920, -2.2953,\n",
      "          0.0321, -0.1037, -0.2622,  0.3548, -1.1990, -0.1450, -2.0992, -1.4839,\n",
      "          0.4222, -1.1548, -2.0719, -0.1832,  0.8736, -0.6605, -1.1264, -0.0073,\n",
      "         -0.7525, -1.0146, -1.6889, -0.3123,  0.2646, -0.9417, -1.5306, -0.9450,\n",
      "         -0.9643, -0.2891, -0.0237, -0.7872,  0.5944,  0.8274,  0.2552,  0.3401]]), tensor([[0.],\n",
      "        [1.],\n",
      "        [0.]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "dropout = 0.5\n",
    "model = nn.Sequential(nn.Linear(40, 40),\n",
    "                     nn.BatchNorm1d(num_features=40)\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(dropout),\n",
    "                     nn.Linear(40, 40),\n",
    "                     nn.BatchNorm1d(num_features=40)\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(dropout),\n",
    "                     nn.Linear(40, 20),\n",
    "                     nn.BatchNorm1d(num_features=20)\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(dropout),\n",
    "                     nn.Linear(20, 10),\n",
    "                     nn.BatchNorm1d(num_features=20)\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(dropout),\n",
    "                     nn.Linear(10, 1),\n",
    "                     nn.Sigmoid())\n",
    "trainset = TensorDataset(torch.from_numpy(ps_x_train).float(), torch.from_numpy(ps_y_train).float())\n",
    "trainloader = DataLoader(trainset, batch_size=3, shuffle=True)\n",
    "testset = TensorDataset(torch.from_numpy(ps_x_test).float(), torch.from_numpy(ps_y_test).float())\n",
    "testloader = DataLoader(testset, batch_size=3, shuffle=True)\n",
    "valset = TensorDataset(torch.from_numpy(ps_x_val).float(), torch.from_numpy(ps_y_val).float())\n",
    "valloader = DataLoader(valset, batch_size=3, shuffle=True)\n",
    "print(next(iter(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print ('Using CUDA: {}'.format(use_cuda))\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, train_loader, val_loader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    # TODO: fix target tensors always zero for some reason\n",
    "    valid_loss_min = np.Inf \n",
    "    print_loss_count = 40\n",
    "    cuda_refresh_count = 5\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        train_load_iter = iter(train_loader)\n",
    "        for i in range(len(train_loader)):\n",
    "            data, target = next(train_load_iter)\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()    \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            train_loss = train_loss + ((1 / (i + 1)) * (loss.data - train_loss))\n",
    "\n",
    "        model.eval()\n",
    "        val_load_iter = iter(val_loader)\n",
    "        for i in range(len(val_loader)):\n",
    "            data, target = next(val_load_iter)\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (i + 1)) * (loss.data - valid_loss))\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        ## save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.690049 \tValidation Loss: 0.693619\n",
      "Validation loss decreased (inf --> 0.693619).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.695588 \tValidation Loss: 0.693593\n",
      "Validation loss decreased (0.693619 --> 0.693593).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.688285 \tValidation Loss: 0.692236\n",
      "Validation loss decreased (0.693593 --> 0.692236).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.689224 \tValidation Loss: 0.691919\n",
      "Validation loss decreased (0.692236 --> 0.691919).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.687510 \tValidation Loss: 0.693624\n",
      "Epoch: 6 \tTraining Loss: 0.690811 \tValidation Loss: 0.693575\n",
      "Epoch: 7 \tTraining Loss: 0.691216 \tValidation Loss: 0.693465\n",
      "Epoch: 8 \tTraining Loss: 0.694043 \tValidation Loss: 0.691568\n",
      "Validation loss decreased (0.691919 --> 0.691568).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.693737 \tValidation Loss: 0.693159\n",
      "Epoch: 10 \tTraining Loss: 0.693104 \tValidation Loss: 0.691234\n",
      "Validation loss decreased (0.691568 --> 0.691234).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.691015 \tValidation Loss: 0.692593\n",
      "Epoch: 12 \tTraining Loss: 0.692378 \tValidation Loss: 0.690989\n",
      "Validation loss decreased (0.691234 --> 0.690989).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.695067 \tValidation Loss: 0.692942\n",
      "Epoch: 14 \tTraining Loss: 0.691991 \tValidation Loss: 0.692893\n",
      "Epoch: 15 \tTraining Loss: 0.693700 \tValidation Loss: 0.692474\n",
      "Epoch: 16 \tTraining Loss: 0.691468 \tValidation Loss: 0.692688\n",
      "Epoch: 17 \tTraining Loss: 0.690940 \tValidation Loss: 0.690495\n",
      "Validation loss decreased (0.690989 --> 0.690495).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.689354 \tValidation Loss: 0.692541\n",
      "Epoch: 19 \tTraining Loss: 0.699275 \tValidation Loss: 0.690453\n",
      "Validation loss decreased (0.690495 --> 0.690453).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.694144 \tValidation Loss: 0.690511\n",
      "Epoch: 21 \tTraining Loss: 0.692919 \tValidation Loss: 0.692324\n",
      "Epoch: 22 \tTraining Loss: 0.695608 \tValidation Loss: 0.690289\n",
      "Validation loss decreased (0.690453 --> 0.690289).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.687536 \tValidation Loss: 0.692174\n",
      "Epoch: 24 \tTraining Loss: 0.691449 \tValidation Loss: 0.690049\n",
      "Validation loss decreased (0.690289 --> 0.690049).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.691631 \tValidation Loss: 0.691879\n",
      "Epoch: 26 \tTraining Loss: 0.691224 \tValidation Loss: 0.689981\n",
      "Validation loss decreased (0.690049 --> 0.689981).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.689431 \tValidation Loss: 0.689763\n",
      "Validation loss decreased (0.689981 --> 0.689763).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.691205 \tValidation Loss: 0.689456\n",
      "Validation loss decreased (0.689763 --> 0.689456).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.688026 \tValidation Loss: 0.691366\n",
      "Epoch: 30 \tTraining Loss: 0.687887 \tValidation Loss: 0.691498\n",
      "Epoch: 31 \tTraining Loss: 0.690344 \tValidation Loss: 0.689190\n",
      "Validation loss decreased (0.689456 --> 0.689190).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.691583 \tValidation Loss: 0.689014\n",
      "Validation loss decreased (0.689190 --> 0.689014).  Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 0.690333 \tValidation Loss: 0.691310\n",
      "Epoch: 34 \tTraining Loss: 0.694750 \tValidation Loss: 0.691131\n",
      "Epoch: 35 \tTraining Loss: 0.689123 \tValidation Loss: 0.690647\n",
      "Epoch: 36 \tTraining Loss: 0.687678 \tValidation Loss: 0.690776\n",
      "Epoch: 37 \tTraining Loss: 0.682587 \tValidation Loss: 0.690750\n",
      "Epoch: 38 \tTraining Loss: 0.685616 \tValidation Loss: 0.688113\n",
      "Validation loss decreased (0.689014 --> 0.688113).  Saving model ...\n",
      "Epoch: 39 \tTraining Loss: 0.690807 \tValidation Loss: 0.687881\n",
      "Validation loss decreased (0.688113 --> 0.687881).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.690178 \tValidation Loss: 0.689966\n",
      "Epoch: 41 \tTraining Loss: 0.693722 \tValidation Loss: 0.689419\n",
      "Epoch: 42 \tTraining Loss: 0.687082 \tValidation Loss: 0.689066\n",
      "Epoch: 43 \tTraining Loss: 0.692870 \tValidation Loss: 0.688777\n",
      "Epoch: 44 \tTraining Loss: 0.689191 \tValidation Loss: 0.689002\n",
      "Epoch: 45 \tTraining Loss: 0.687939 \tValidation Loss: 0.688301\n",
      "Epoch: 46 \tTraining Loss: 0.686910 \tValidation Loss: 0.685504\n",
      "Validation loss decreased (0.687881 --> 0.685504).  Saving model ...\n",
      "Epoch: 47 \tTraining Loss: 0.691301 \tValidation Loss: 0.687606\n",
      "Epoch: 48 \tTraining Loss: 0.686427 \tValidation Loss: 0.687315\n",
      "Epoch: 49 \tTraining Loss: 0.686486 \tValidation Loss: 0.684777\n",
      "Validation loss decreased (0.685504 --> 0.684777).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.689455 \tValidation Loss: 0.687207\n",
      "Epoch: 51 \tTraining Loss: 0.686543 \tValidation Loss: 0.686138\n",
      "Epoch: 52 \tTraining Loss: 0.688234 \tValidation Loss: 0.683138\n",
      "Validation loss decreased (0.684777 --> 0.683138).  Saving model ...\n",
      "Epoch: 53 \tTraining Loss: 0.684459 \tValidation Loss: 0.682630\n",
      "Validation loss decreased (0.683138 --> 0.682630).  Saving model ...\n",
      "Epoch: 54 \tTraining Loss: 0.685918 \tValidation Loss: 0.684835\n",
      "Epoch: 55 \tTraining Loss: 0.686956 \tValidation Loss: 0.680939\n",
      "Validation loss decreased (0.682630 --> 0.680939).  Saving model ...\n",
      "Epoch: 56 \tTraining Loss: 0.685929 \tValidation Loss: 0.681615\n",
      "Epoch: 57 \tTraining Loss: 0.689491 \tValidation Loss: 0.680938\n",
      "Validation loss decreased (0.680939 --> 0.680938).  Saving model ...\n",
      "Epoch: 58 \tTraining Loss: 0.690384 \tValidation Loss: 0.680394\n",
      "Validation loss decreased (0.680938 --> 0.680394).  Saving model ...\n",
      "Epoch: 59 \tTraining Loss: 0.674841 \tValidation Loss: 0.681971\n",
      "Epoch: 60 \tTraining Loss: 0.686087 \tValidation Loss: 0.678584\n",
      "Validation loss decreased (0.680394 --> 0.678584).  Saving model ...\n",
      "Epoch: 61 \tTraining Loss: 0.683893 \tValidation Loss: 0.677393\n",
      "Validation loss decreased (0.678584 --> 0.677393).  Saving model ...\n",
      "Epoch: 62 \tTraining Loss: 0.686079 \tValidation Loss: 0.678631\n",
      "Epoch: 63 \tTraining Loss: 0.683970 \tValidation Loss: 0.678353\n",
      "Epoch: 64 \tTraining Loss: 0.688070 \tValidation Loss: 0.673706\n",
      "Validation loss decreased (0.677393 --> 0.673706).  Saving model ...\n",
      "Epoch: 65 \tTraining Loss: 0.684004 \tValidation Loss: 0.677135\n",
      "Epoch: 66 \tTraining Loss: 0.684587 \tValidation Loss: 0.672687\n",
      "Validation loss decreased (0.673706 --> 0.672687).  Saving model ...\n",
      "Epoch: 67 \tTraining Loss: 0.681078 \tValidation Loss: 0.670454\n",
      "Validation loss decreased (0.672687 --> 0.670454).  Saving model ...\n",
      "Epoch: 68 \tTraining Loss: 0.675695 \tValidation Loss: 0.669087\n",
      "Validation loss decreased (0.670454 --> 0.669087).  Saving model ...\n",
      "Epoch: 69 \tTraining Loss: 0.670602 \tValidation Loss: 0.666404\n",
      "Validation loss decreased (0.669087 --> 0.666404).  Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 0.667859 \tValidation Loss: 0.665403\n",
      "Validation loss decreased (0.666404 --> 0.665403).  Saving model ...\n",
      "Epoch: 71 \tTraining Loss: 0.674808 \tValidation Loss: 0.666082\n",
      "Epoch: 72 \tTraining Loss: 0.665941 \tValidation Loss: 0.663336\n",
      "Validation loss decreased (0.665403 --> 0.663336).  Saving model ...\n",
      "Epoch: 73 \tTraining Loss: 0.668029 \tValidation Loss: 0.656984\n",
      "Validation loss decreased (0.663336 --> 0.656984).  Saving model ...\n",
      "Epoch: 74 \tTraining Loss: 0.663958 \tValidation Loss: 0.656496\n",
      "Validation loss decreased (0.656984 --> 0.656496).  Saving model ...\n",
      "Epoch: 75 \tTraining Loss: 0.656437 \tValidation Loss: 0.647591\n",
      "Validation loss decreased (0.656496 --> 0.647591).  Saving model ...\n",
      "Epoch: 76 \tTraining Loss: 0.675543 \tValidation Loss: 0.650138\n",
      "Epoch: 77 \tTraining Loss: 0.675804 \tValidation Loss: 0.645332\n",
      "Validation loss decreased (0.647591 --> 0.645332).  Saving model ...\n",
      "Epoch: 78 \tTraining Loss: 0.663248 \tValidation Loss: 0.642072\n",
      "Validation loss decreased (0.645332 --> 0.642072).  Saving model ...\n",
      "Epoch: 79 \tTraining Loss: 0.644054 \tValidation Loss: 0.636235\n",
      "Validation loss decreased (0.642072 --> 0.636235).  Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 0.664757 \tValidation Loss: 0.636795\n",
      "Epoch: 81 \tTraining Loss: 0.649298 \tValidation Loss: 0.628948\n",
      "Validation loss decreased (0.636235 --> 0.628948).  Saving model ...\n",
      "Epoch: 82 \tTraining Loss: 0.661347 \tValidation Loss: 0.626199\n",
      "Validation loss decreased (0.628948 --> 0.626199).  Saving model ...\n",
      "Epoch: 83 \tTraining Loss: 0.660625 \tValidation Loss: 0.625643\n",
      "Validation loss decreased (0.626199 --> 0.625643).  Saving model ...\n",
      "Epoch: 84 \tTraining Loss: 0.672527 \tValidation Loss: 0.623579\n",
      "Validation loss decreased (0.625643 --> 0.623579).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 \tTraining Loss: 0.642284 \tValidation Loss: 0.616976\n",
      "Validation loss decreased (0.623579 --> 0.616976).  Saving model ...\n",
      "Epoch: 86 \tTraining Loss: 0.645213 \tValidation Loss: 0.613876\n",
      "Validation loss decreased (0.616976 --> 0.613876).  Saving model ...\n",
      "Epoch: 87 \tTraining Loss: 0.630927 \tValidation Loss: 0.606076\n",
      "Validation loss decreased (0.613876 --> 0.606076).  Saving model ...\n",
      "Epoch: 88 \tTraining Loss: 0.645595 \tValidation Loss: 0.600789\n",
      "Validation loss decreased (0.606076 --> 0.600789).  Saving model ...\n",
      "Epoch: 89 \tTraining Loss: 0.631247 \tValidation Loss: 0.597008\n",
      "Validation loss decreased (0.600789 --> 0.597008).  Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 0.637604 \tValidation Loss: 0.593480\n",
      "Validation loss decreased (0.597008 --> 0.593480).  Saving model ...\n",
      "Epoch: 91 \tTraining Loss: 0.637020 \tValidation Loss: 0.587734\n",
      "Validation loss decreased (0.593480 --> 0.587734).  Saving model ...\n",
      "Epoch: 92 \tTraining Loss: 0.629573 \tValidation Loss: 0.585492\n",
      "Validation loss decreased (0.587734 --> 0.585492).  Saving model ...\n",
      "Epoch: 93 \tTraining Loss: 0.608144 \tValidation Loss: 0.579812\n",
      "Validation loss decreased (0.585492 --> 0.579812).  Saving model ...\n",
      "Epoch: 94 \tTraining Loss: 0.625837 \tValidation Loss: 0.578266\n",
      "Validation loss decreased (0.579812 --> 0.578266).  Saving model ...\n",
      "Epoch: 95 \tTraining Loss: 0.651091 \tValidation Loss: 0.575354\n",
      "Validation loss decreased (0.578266 --> 0.575354).  Saving model ...\n",
      "Epoch: 96 \tTraining Loss: 0.616878 \tValidation Loss: 0.574663\n",
      "Validation loss decreased (0.575354 --> 0.574663).  Saving model ...\n",
      "Epoch: 97 \tTraining Loss: 0.621740 \tValidation Loss: 0.575839\n",
      "Epoch: 98 \tTraining Loss: 0.619244 \tValidation Loss: 0.561893\n",
      "Validation loss decreased (0.574663 --> 0.561893).  Saving model ...\n",
      "Epoch: 99 \tTraining Loss: 0.603597 \tValidation Loss: 0.556473\n",
      "Validation loss decreased (0.561893 --> 0.556473).  Saving model ...\n",
      "Epoch: 100 \tTraining Loss: 0.614416 \tValidation Loss: 0.559167\n",
      "Epoch: 101 \tTraining Loss: 0.603330 \tValidation Loss: 0.556559\n",
      "Epoch: 102 \tTraining Loss: 0.634130 \tValidation Loss: 0.546855\n",
      "Validation loss decreased (0.556473 --> 0.546855).  Saving model ...\n",
      "Epoch: 103 \tTraining Loss: 0.603404 \tValidation Loss: 0.557574\n",
      "Epoch: 104 \tTraining Loss: 0.618538 \tValidation Loss: 0.550092\n",
      "Epoch: 105 \tTraining Loss: 0.591129 \tValidation Loss: 0.539318\n",
      "Validation loss decreased (0.546855 --> 0.539318).  Saving model ...\n",
      "Epoch: 106 \tTraining Loss: 0.585076 \tValidation Loss: 0.533475\n",
      "Validation loss decreased (0.539318 --> 0.533475).  Saving model ...\n",
      "Epoch: 107 \tTraining Loss: 0.608323 \tValidation Loss: 0.532183\n",
      "Validation loss decreased (0.533475 --> 0.532183).  Saving model ...\n",
      "Epoch: 108 \tTraining Loss: 0.598406 \tValidation Loss: 0.533252\n",
      "Epoch: 109 \tTraining Loss: 0.577329 \tValidation Loss: 0.534941\n",
      "Epoch: 110 \tTraining Loss: 0.613240 \tValidation Loss: 0.531100\n",
      "Validation loss decreased (0.532183 --> 0.531100).  Saving model ...\n",
      "Epoch: 111 \tTraining Loss: 0.590765 \tValidation Loss: 0.525598\n",
      "Validation loss decreased (0.531100 --> 0.525598).  Saving model ...\n",
      "Epoch: 112 \tTraining Loss: 0.572711 \tValidation Loss: 0.534839\n",
      "Epoch: 113 \tTraining Loss: 0.583034 \tValidation Loss: 0.526441\n",
      "Epoch: 114 \tTraining Loss: 0.569262 \tValidation Loss: 0.514766\n",
      "Validation loss decreased (0.525598 --> 0.514766).  Saving model ...\n",
      "Epoch: 115 \tTraining Loss: 0.586997 \tValidation Loss: 0.509333\n",
      "Validation loss decreased (0.514766 --> 0.509333).  Saving model ...\n",
      "Epoch: 116 \tTraining Loss: 0.576048 \tValidation Loss: 0.529544\n",
      "Epoch: 117 \tTraining Loss: 0.580298 \tValidation Loss: 0.513200\n",
      "Epoch: 118 \tTraining Loss: 0.547516 \tValidation Loss: 0.508868\n",
      "Validation loss decreased (0.509333 --> 0.508868).  Saving model ...\n",
      "Epoch: 119 \tTraining Loss: 0.561593 \tValidation Loss: 0.507359\n",
      "Validation loss decreased (0.508868 --> 0.507359).  Saving model ...\n",
      "Epoch: 120 \tTraining Loss: 0.574242 \tValidation Loss: 0.509110\n",
      "Epoch: 121 \tTraining Loss: 0.544986 \tValidation Loss: 0.505942\n",
      "Validation loss decreased (0.507359 --> 0.505942).  Saving model ...\n",
      "Epoch: 122 \tTraining Loss: 0.571138 \tValidation Loss: 0.505308\n",
      "Validation loss decreased (0.505942 --> 0.505308).  Saving model ...\n",
      "Epoch: 123 \tTraining Loss: 0.581850 \tValidation Loss: 0.498588\n",
      "Validation loss decreased (0.505308 --> 0.498588).  Saving model ...\n",
      "Epoch: 124 \tTraining Loss: 0.524614 \tValidation Loss: 0.492493\n",
      "Validation loss decreased (0.498588 --> 0.492493).  Saving model ...\n",
      "Epoch: 125 \tTraining Loss: 0.579920 \tValidation Loss: 0.502374\n",
      "Epoch: 126 \tTraining Loss: 0.577372 \tValidation Loss: 0.513591\n",
      "Epoch: 127 \tTraining Loss: 0.550389 \tValidation Loss: 0.496106\n",
      "Epoch: 128 \tTraining Loss: 0.581765 \tValidation Loss: 0.501856\n",
      "Epoch: 129 \tTraining Loss: 0.537465 \tValidation Loss: 0.501113\n",
      "Epoch: 130 \tTraining Loss: 0.541886 \tValidation Loss: 0.522290\n",
      "Epoch: 131 \tTraining Loss: 0.557304 \tValidation Loss: 0.499928\n",
      "Epoch: 132 \tTraining Loss: 0.527002 \tValidation Loss: 0.494055\n",
      "Epoch: 133 \tTraining Loss: 0.513320 \tValidation Loss: 0.526438\n",
      "Epoch: 134 \tTraining Loss: 0.527289 \tValidation Loss: 0.501108\n",
      "Epoch: 135 \tTraining Loss: 0.569213 \tValidation Loss: 0.490989\n",
      "Validation loss decreased (0.492493 --> 0.490989).  Saving model ...\n",
      "Epoch: 136 \tTraining Loss: 0.507565 \tValidation Loss: 0.486271\n",
      "Validation loss decreased (0.490989 --> 0.486271).  Saving model ...\n",
      "Epoch: 137 \tTraining Loss: 0.545864 \tValidation Loss: 0.495063\n",
      "Epoch: 138 \tTraining Loss: 0.540210 \tValidation Loss: 0.506704\n",
      "Epoch: 139 \tTraining Loss: 0.525675 \tValidation Loss: 0.494941\n",
      "Epoch: 140 \tTraining Loss: 0.520722 \tValidation Loss: 0.491523\n",
      "Epoch: 141 \tTraining Loss: 0.553594 \tValidation Loss: 0.493276\n",
      "Epoch: 142 \tTraining Loss: 0.519091 \tValidation Loss: 0.495829\n",
      "Epoch: 143 \tTraining Loss: 0.486776 \tValidation Loss: 0.482890\n",
      "Validation loss decreased (0.486271 --> 0.482890).  Saving model ...\n",
      "Epoch: 144 \tTraining Loss: 0.553335 \tValidation Loss: 0.497912\n",
      "Epoch: 145 \tTraining Loss: 0.520643 \tValidation Loss: 0.496550\n",
      "Epoch: 146 \tTraining Loss: 0.512977 \tValidation Loss: 0.529957\n",
      "Epoch: 147 \tTraining Loss: 0.518498 \tValidation Loss: 0.504847\n",
      "Epoch: 148 \tTraining Loss: 0.477337 \tValidation Loss: 0.494260\n",
      "Epoch: 149 \tTraining Loss: 0.522302 \tValidation Loss: 0.501217\n",
      "Epoch: 150 \tTraining Loss: 0.509322 \tValidation Loss: 0.503921\n"
     ]
    }
   ],
   "source": [
    "model = train(150, trainloader, valloader, model, optimizer, criterion,\n",
    "                      use_cuda, 'model_nn1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_nn1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, criterion, use_cuda, num_classes = 2):\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    model.eval()\n",
    "    load_iter = iter(loader)\n",
    "    for i in range(len(loader)):\n",
    "        data, target = next(load_iter)\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (i + 1)) * (loss.data - test_loss))\n",
    "        # compare predictions to true label\n",
    "        for j, tensor in enumerate(output):\n",
    "            if (tensor.item() > .5 and target[j] == 1) or (tensor.item() <= .5 and target[j] == 0):\n",
    "                correct += 1\n",
    "        total += data.size(0)\n",
    "       \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.612423\n",
      "\n",
      "\n",
      "Test Accuracy: 69% (69/100)\n"
     ]
    }
   ],
   "source": [
    "test(testloader, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n2018 Bracket\\nschool_names_south = [\\n    # south region\\n    ('Virginia', 1),('Maryland-Baltimore County', 16),\\n    ('Creighton', 8), ('Kansas State', 9),\\n    ('Kentucky',5), ('Davidson', 12),\\n    ('Arizona',4), ('Buffalo', 13),\\n    ('Miami (FL)', 6), ('Loyola (IL)', 11),\\n    ('Tennessee',3), ('Wright State',14),\\n    ('Nevada',7),('Texas',10),\\n    ('Cincinnati',2), ('Georgia State',15)\\n    ]\\nschool_names_west = [\\n    # west region\\n    ('Xavier', 1),('North Carolina Central',16), #or 'Texas Southern',\\n    ('Missouri', 8),('Florida State', 9),\\n    ('Ohio State',5), ('South Dakota State', 12),\\n    ('Gonzaga',4), ('North Carolina-Greensboro',13),\\n    ('Houston',6),('San Diego State',11),\\n    ('Michigan', 3),('Montana', 14),\\n    ('Texas A&M',7),('Providence',10),\\n    ('North Carolina',2),('Lipscomb',15)\\n    ]\\nschool_names_east = [\\n    # east region\\n    ('Villanova',1),('Long Island University',16), # or 'Radford',\\n    ('Virginia Tech',8), ('Alabama',9),\\n    ('West Virginia',5), ('Murray State',12),\\n    ('Wichita State',4), ('Marshall',13),\\n    ('Florida',6), ('St. Bonaventure',11), # or 'UCLA',\\n    ('Texas Tech',3), ('Stephen F. Austin',14),\\n    ('Arkansas',7), ('Butler',10),\\n    ('Purdue', 2), ('Cal State Fullerton',15)\\n    ]\\nschool_names_midwest = [\\n    # mid-west region\\n    ('Kansas', 1), ('Pennsylvania',16),\\n    ('Seton Hall', 8), ('North Carolina State',9),\\n    ('Clemson', 5), ('New Mexico State',12),\\n    ('Auburn',4), ('College of Charleston',13),\\n    ('Texas Christian',6), ('Arizona State',11), # or 'Syracuse',\\n    ('Michigan State',3), ('Bucknell',14),\\n    ('Rhode Island',7), ('Oklahoma',10),\\n    ('Duke', 2), ('Iona' ,15) \\n    ]\\n\""
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup This years bracket regions\n",
    "# TODO: automate this with the data received from the scraper\n",
    "school_names_south = [\n",
    "    # south region\n",
    "    ('Virginia', 1),('Gardner-Webb', 16),\n",
    "    ('Ole Miss', 8), ('Oklahoma', 9),\n",
    "    ('Wisconsin',5), ('Oregon', 12),\n",
    "    ('Kansas State',4), ('UC-Irvine', 13),\n",
    "    ('Villanova', 6), (\"Saint Mary's\", 11),\n",
    "    ('Purdue',3), ('Old Dominion',14),\n",
    "    ('Cincinnati',7),('Iowa',10),\n",
    "    ('Tennessee',2), ('Colgate',15)\n",
    "    ]\n",
    "school_names_west = [\n",
    "    # west region\n",
    "    ('Gonzaga', 1),('North Carolina Central',16), #or 'Texas Southern',\n",
    "    ('Syracuse', 8),('Baylor', 9),\n",
    "    ('Marquette',5), ('Murray State', 12),\n",
    "    ('Florida State',4), ('Vermont',13),\n",
    "    ('Buffalo',6),('San Diego State',11), # or\n",
    "    ('Texas Tech', 3),('Northern Kentucky', 14),\n",
    "    ('Nevada',7),('Florida',10),\n",
    "    ('Michigan',2),('Montana',15)\n",
    "    ]\n",
    "school_names_east = [\n",
    "    # east region\n",
    "    ('Duke',1),('Long Island University',16), # or 'Radford',\n",
    "    ('VCU',8), ('UCF',9),\n",
    "    ('Mississippi State',5), ('Liberty',12),\n",
    "    ('Virginia Tech',4), ('Saint Louis',13),\n",
    "    ('Maryland',6), ('St. Bonaventure',11), # or 'UCLA',\n",
    "    ('LSU',3), ('Yale',14),\n",
    "    ('Louisville',7), ('Minnesota',10),\n",
    "    ('Michigan State', 2), ('Bradley',15)\n",
    "    ]\n",
    "school_names_midwest = [\n",
    "    # mid-west region\n",
    "    ('UNC', 1),('Iona', 16),\n",
    "    ('Utah State', 8), ('Washington', 9),\n",
    "    ('Auburn',5), ('New Mexico State', 12),\n",
    "    ('Kansas',4), ('Northeastern', 13),\n",
    "    ('Iowa State', 6), ('Ohio State', 11),\n",
    "    ('Houston',3), ('Georgia State',14),\n",
    "    ('Wofford',7),('Seton Hall',10),\n",
    "    ('Kentucky',2), ('Abilene Christian',15)\n",
    "    ]\n",
    "'''\n",
    "2018 Bracket\n",
    "school_names_south = [\n",
    "    # south region\n",
    "    ('Virginia', 1),('Maryland-Baltimore County', 16),\n",
    "    ('Creighton', 8), ('Kansas State', 9),\n",
    "    ('Kentucky',5), ('Davidson', 12),\n",
    "    ('Arizona',4), ('Buffalo', 13),\n",
    "    ('Miami (FL)', 6), ('Loyola (IL)', 11),\n",
    "    ('Tennessee',3), ('Wright State',14),\n",
    "    ('Nevada',7),('Texas',10),\n",
    "    ('Cincinnati',2), ('Georgia State',15)\n",
    "    ]\n",
    "school_names_west = [\n",
    "    # west region\n",
    "    ('Xavier', 1),('North Carolina Central',16), #or 'Texas Southern',\n",
    "    ('Missouri', 8),('Florida State', 9),\n",
    "    ('Ohio State',5), ('South Dakota State', 12),\n",
    "    ('Gonzaga',4), ('North Carolina-Greensboro',13),\n",
    "    ('Houston',6),('San Diego State',11),\n",
    "    ('Michigan', 3),('Montana', 14),\n",
    "    ('Texas A&M',7),('Providence',10),\n",
    "    ('North Carolina',2),('Lipscomb',15)\n",
    "    ]\n",
    "school_names_east = [\n",
    "    # east region\n",
    "    ('Villanova',1),('Long Island University',16), # or 'Radford',\n",
    "    ('Virginia Tech',8), ('Alabama',9),\n",
    "    ('West Virginia',5), ('Murray State',12),\n",
    "    ('Wichita State',4), ('Marshall',13),\n",
    "    ('Florida',6), ('St. Bonaventure',11), # or 'UCLA',\n",
    "    ('Texas Tech',3), ('Stephen F. Austin',14),\n",
    "    ('Arkansas',7), ('Butler',10),\n",
    "    ('Purdue', 2), ('Cal State Fullerton',15)\n",
    "    ]\n",
    "school_names_midwest = [\n",
    "    # mid-west region\n",
    "    ('Kansas', 1), ('Pennsylvania',16),\n",
    "    ('Seton Hall', 8), ('North Carolina State',9),\n",
    "    ('Clemson', 5), ('New Mexico State',12),\n",
    "    ('Auburn',4), ('College of Charleston',13),\n",
    "    ('Texas Christian',6), ('Arizona State',11), # or 'Syracuse',\n",
    "    ('Michigan State',3), ('Bucknell',14),\n",
    "    ('Rhode Island',7), ('Oklahoma',10),\n",
    "    ('Duke', 2), ('Iona' ,15) \n",
    "    ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Methods to add evaluating the predicted winners of matchups and subbrackets (A region or Final Four)\n",
    "    To change the predictive model used, just change the model handed to \"evaluate_winner(schools,sub_bracket_name, model)\"\n",
    "    found later in the notebook\n",
    "'''\n",
    "def get_matchup_winners(matchup_stats, schools, model, post_season, use_cuda):\n",
    "    x_tourney = matchup_stats[shared.ps_feature_col_names].values\n",
    "    x_tourney = torch.from_numpy(x_tourney).float()\n",
    "    # print(x_tourney)\n",
    "    if use_cuda:\n",
    "        x_tourney = x_tourney.cuda()\n",
    "    y_tourney = model(x_tourney)\n",
    "    print(y_tourney)\n",
    "    i = 0\n",
    "    winners = []\n",
    "    for y_val in y_tourney:\n",
    "        t1_name, t1_seed = schools[i]\n",
    "        t2_name, t2_seed = schools[i + 1]\n",
    "        print('t1 win?: {}'.format(y_val.item()))\n",
    "        t1_won = y_val.item() > .5\n",
    "        print(t1_name,t1_seed,' vs. ', t2_name,t2_seed,'(team 1 won=', t1_won,')')\n",
    "        if(t1_won):\n",
    "            winners.append((t1_name,t1_seed))\n",
    "        else:\n",
    "            winners.append((t2_name, t2_seed))\n",
    "        i = i + 2\n",
    "    return winners\n",
    "def evaluate_winner(schools,sub_bracket_name, model, use_cuda):        \n",
    "    remaining_teams = schools\n",
    "    i = 1\n",
    "    while(len(remaining_teams) > 1):\n",
    "        #Add a random factor\n",
    "        rand = random.randrange(0,1)\n",
    "        post_season_stats = True\n",
    "        print(\"---\",sub_bracket_name,\" round \",i,\"---\")\n",
    "        matchup_stats = shared.get_matchups_stats(df_school, remaining_teams, post_season_stats)\n",
    "        remaining_teams = get_matchup_winners(matchup_stats,remaining_teams, model, post_season_stats, use_cuda)\n",
    "        i = i + 1\n",
    "    winner = remaining_teams[0]\n",
    "    print('Winner of ',sub_bracket_name,':',winner)\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- South  round  1 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Virginia 1  vs.  Gardner-Webb 16 (team 1 won= True )\n",
      "t1 win?: 0.9999995231628418\n",
      "Ole Miss 8  vs.  Oklahoma 9 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Wisconsin 5  vs.  Oregon 12 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Kansas State 4  vs.  UC-Irvine 13 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Villanova 6  vs.  Saint Mary's 11 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Purdue 3  vs.  Old Dominion 14 (team 1 won= True )\n",
      "t1 win?: 0.9999998807907104\n",
      "Cincinnati 7  vs.  Iowa 10 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Tennessee 2  vs.  Colgate 15 (team 1 won= True )\n",
      "--- South  round  2 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Virginia 1  vs.  Ole Miss 8 (team 1 won= True )\n",
      "t1 win?: 0.9999995231628418\n",
      "Wisconsin 5  vs.  Kansas State 4 (team 1 won= True )\n",
      "t1 win?: 0.9999754428863525\n",
      "Villanova 6  vs.  Purdue 3 (team 1 won= True )\n",
      "t1 win?: 0.9999850988388062\n",
      "Cincinnati 7  vs.  Tennessee 2 (team 1 won= True )\n",
      "--- South  round  3 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 0.9999996423721313\n",
      "Virginia 1  vs.  Wisconsin 5 (team 1 won= True )\n",
      "t1 win?: 0.9999998807907104\n",
      "Villanova 6  vs.  Cincinnati 7 (team 1 won= True )\n",
      "--- South  round  4 ---\n",
      "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Virginia 1  vs.  Villanova 6 (team 1 won= True )\n",
      "Winner of  South : ('Virginia', 1)\n",
      "--- West  round  1 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Gonzaga 1  vs.  North Carolina Central 16 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Syracuse 8  vs.  Baylor 9 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Marquette 5  vs.  Murray State 12 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Florida State 4  vs.  Vermont 13 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Buffalo 6  vs.  San Diego State 11 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Texas Tech 3  vs.  Northern Kentucky 14 (team 1 won= True )\n",
      "t1 win?: 0.9999986886978149\n",
      "Nevada 7  vs.  Florida 10 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Michigan 2  vs.  Montana 15 (team 1 won= True )\n",
      "--- West  round  2 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9998]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Gonzaga 1  vs.  Syracuse 8 (team 1 won= True )\n",
      "t1 win?: 0.999998927116394\n",
      "Marquette 5  vs.  Florida State 4 (team 1 won= True )\n",
      "t1 win?: 0.9999974966049194\n",
      "Buffalo 6  vs.  Texas Tech 3 (team 1 won= True )\n",
      "t1 win?: 0.9998254179954529\n",
      "Nevada 7  vs.  Michigan 2 (team 1 won= True )\n",
      "--- West  round  3 ---\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Gonzaga 1  vs.  Marquette 5 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Buffalo 6  vs.  Nevada 7 (team 1 won= True )\n",
      "--- West  round  4 ---\n",
      "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Gonzaga 1  vs.  Buffalo 6 (team 1 won= True )\n",
      "Winner of  West : ('Gonzaga', 1)\n",
      "--- East  round  1 ---\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Duke 1  vs.  Long Island University 16 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "VCU 8  vs.  UCF 9 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Mississippi State 5  vs.  Liberty 12 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Virginia Tech 4  vs.  Saint Louis 13 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Maryland 6  vs.  St. Bonaventure 11 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "LSU 3  vs.  Yale 14 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Louisville 7  vs.  Minnesota 10 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Michigan State 2  vs.  Bradley 15 (team 1 won= True )\n",
      "--- East  round  2 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Duke 1  vs.  VCU 8 (team 1 won= True )\n",
      "t1 win?: 0.9999996423721313\n",
      "Mississippi State 5  vs.  Virginia Tech 4 (team 1 won= True )\n",
      "t1 win?: 0.9999992847442627\n",
      "Maryland 6  vs.  LSU 3 (team 1 won= True )\n",
      "t1 win?: 0.9999796152114868\n",
      "Louisville 7  vs.  Michigan State 2 (team 1 won= True )\n",
      "--- East  round  3 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Duke 1  vs.  Mississippi State 5 (team 1 won= True )\n",
      "t1 win?: 0.9999992847442627\n",
      "Maryland 6  vs.  Louisville 7 (team 1 won= True )\n",
      "--- East  round  4 ---\n",
      "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "Duke 1  vs.  Maryland 6 (team 1 won= True )\n",
      "Winner of  East : ('Duke', 1)\n",
      "--- MidWest  round  1 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "UNC 1  vs.  Iona 16 (team 1 won= True )\n",
      "t1 win?: 0.9999997615814209\n",
      "Utah State 8  vs.  Washington 9 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Auburn 5  vs.  New Mexico State 12 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Kansas 4  vs.  Northeastern 13 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Iowa State 6  vs.  Ohio State 11 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Houston 3  vs.  Georgia State 14 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Wofford 7  vs.  Seton Hall 10 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Kentucky 2  vs.  Abilene Christian 15 (team 1 won= True )\n",
      "--- MidWest  round  2 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "UNC 1  vs.  Utah State 8 (team 1 won= True )\n",
      "t1 win?: 0.9999998807907104\n",
      "Auburn 5  vs.  Kansas 4 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Iowa State 6  vs.  Houston 3 (team 1 won= True )\n",
      "t1 win?: 0.9999955892562866\n",
      "Wofford 7  vs.  Kentucky 2 (team 1 won= True )\n",
      "--- MidWest  round  3 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 0.9999997615814209\n",
      "UNC 1  vs.  Auburn 5 (team 1 won= True )\n",
      "t1 win?: 1.0\n",
      "Iowa State 6  vs.  Wofford 7 (team 1 won= True )\n",
      "--- MidWest  round  4 ---\n",
      "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 1.0\n",
      "UNC 1  vs.  Iowa State 6 (team 1 won= True )\n",
      "Winner of  MidWest : ('UNC', 1)\n"
     ]
    }
   ],
   "source": [
    "# Get predicted final four\n",
    "\n",
    "final_four = [evaluate_winner(school_names_south, \"South\",model, use_cuda), evaluate_winner(school_names_west,\"West\",model, use_cuda),\n",
    "              evaluate_winner(school_names_east, \"East\", model, use_cuda), evaluate_winner(school_names_midwest, \"MidWest\",model, use_cuda)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Virginia', 1), ('Gonzaga', 1), ('Duke', 1), ('UNC', 1)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FinalFour  round  1 ---\n",
      "tensor([[1.0000],\n",
      "        [1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 0.9999998807907104\n",
      "Virginia 1  vs.  Gonzaga 1 (team 1 won= True )\n",
      "t1 win?: 0.9999998807907104\n",
      "Duke 1  vs.  UNC 1 (team 1 won= True )\n",
      "--- FinalFour  round  2 ---\n",
      "tensor([[0.9999]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "t1 win?: 0.9999279975891113\n",
      "Virginia 1  vs.  Duke 1 (team 1 won= True )\n",
      "Winner of  FinalFour : ('Virginia', 1)\n"
     ]
    }
   ],
   "source": [
    "champ = evaluate_winner(final_four, \"FinalFour\", model, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
