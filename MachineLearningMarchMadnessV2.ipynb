{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5005fd2c",
   "metadata": {},
   "source": [
    "# Prediction March Madness V2\n",
    "\n",
    "This notebook contains a refactored and improved version of the March Madness prediction model. Key improvements include:\n",
    "1. Vectorized data preparation for faster execution.\n",
    "2. Use of scikit-learn `Pipeline` for cleaner preprocessing.\n",
    "3. Feature engineering (seed differentials, point differentials).\n",
    "4. Component-based architecture using `shared.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda828f4",
   "metadata": {},
   "source": [
    "## 1. Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5c072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import shared\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b63f9",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf2d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Stats Shape: (5300, 21)\n",
      "Post Season Games Shape: (818, 7)\n"
     ]
    }
   ],
   "source": [
    "df_team = pd.read_csv(\"data/team_yearly_stats.csv\")\n",
    "df_ps_game = pd.read_csv(\"data/post_season_games.csv\")\n",
    "\n",
    "print(f\"Team Stats Shape: {df_team.shape}\")\n",
    "print(f\"Post Season Games Shape: {df_ps_game.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26db984a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'shared' has no attribute 'get_team_stats_df_vectorized'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use the new vectorized merge function from shared.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_full = \u001b[43mshared\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_team_stats_df_vectorized\u001b[49m(df_team, df_ps_game)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMerged Data Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_full.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m df_full.head()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'shared' has no attribute 'get_team_stats_df_vectorized'"
     ]
    }
   ],
   "source": [
    "# Use the new vectorized merge function from shared.py\n",
    "df_full = shared.get_team_stats_df_vectorized(df_team, df_ps_game)\n",
    "print(f\"Merged Data Shape: {df_full.shape}\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47d321",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "We calculate differentials between teams, which are often more predictive than raw stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11606fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_differentials(df):\n",
    "    df = df.copy()\n",
    "    df['seed_diff'] = df['team_1_seed'] - df['team_2_seed']\n",
    "    df['pt_diff_1'] = df['pt_pg_1'] - df['opnt_pt_pg_1']\n",
    "    df['pt_diff_2'] = df['pt_pg_2'] - df['opnt_pt_pg_2']\n",
    "    df['srs_diff'] = df['srs_1'] - df['srs_2']\n",
    "    df['sos_diff'] = df['sos_1'] - df['sos_2']\n",
    "    df['win_pct_diff'] = df['wl_pct_1'] - df['wl_pct_2']\n",
    "    return df\n",
    "\n",
    "df_full = add_differentials(df_full)\n",
    "\n",
    "# Update feature names to include the new differentials\n",
    "features = shared.ps_feature_col_names + ['seed_diff', 'srs_diff', 'sos_diff', 'win_pct_diff']\n",
    "target = 't1_win'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9454177",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_full[features]\n",
    "y = df_full[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set balance:\\n{y_train.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b7b74",
   "metadata": {},
   "source": [
    "## 5. Modeling Pipeline\n",
    "\n",
    "We use a pipeline to handle imputation and scaling consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc8bdb",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd94114",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32ac31",
   "metadata": {},
   "source": [
    "## 7. Feature Importance\n",
    "\n",
    "Let's see which features the model relies on most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25beb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = best_model.named_steps['classifier'].coef_[0]\n",
    "feature_importance = pd.DataFrame({'feature': features, 'importance': np.abs(coeffs)})\n",
    "feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "plt.title('Top 20 Features by Importance (Logistic Regression Coefficients)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9ba29-021c-4de5-97f3-4a9d2bcb3d69",
   "metadata": {},
   "source": [
    "# We have trained our models, not experiment with them to produce your bracket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b253498-436d-47f4-914e-0f0796e7ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shared.evaluate_tournament(df_team, best_model, features=features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
