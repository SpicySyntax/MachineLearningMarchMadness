{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction March Madness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #dataframes\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np # n-dim object support\n",
    "# do ploting inline instead of in a separate window\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team = pd.read_csv(\"data/team_yearly_stats.csv\")\n",
    "df_ps_game = pd.read_csv(\"data/post_season_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 7)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4574, 21)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_team.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_name</th>\n",
       "      <th>fg_pg</th>\n",
       "      <th>ft_pg</th>\n",
       "      <th>three_pt_pg</th>\n",
       "      <th>orb_pg</th>\n",
       "      <th>drb_pg</th>\n",
       "      <th>ast_pg</th>\n",
       "      <th>stl_pg</th>\n",
       "      <th>blk_pg</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_pg</th>\n",
       "      <th>pt_pg</th>\n",
       "      <th>opnt_pt_pg</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>three_p_pct</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>wl_pct</th>\n",
       "      <th>conf_wl_pct</th>\n",
       "      <th>srs</th>\n",
       "      <th>sos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>22.562500</td>\n",
       "      <td>13.062500</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>5.843750</td>\n",
       "      <td>28.504883</td>\n",
       "      <td>15.437500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>...</td>\n",
       "      <td>17.593750</td>\n",
       "      <td>64.812500</td>\n",
       "      <td>65.062500</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>Akron</td>\n",
       "      <td>24.777778</td>\n",
       "      <td>12.694444</td>\n",
       "      <td>7.861111</td>\n",
       "      <td>10.083333</td>\n",
       "      <td>34.108796</td>\n",
       "      <td>14.444444</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>...</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>70.111111</td>\n",
       "      <td>65.694444</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>22.607143</td>\n",
       "      <td>14.892857</td>\n",
       "      <td>4.464286</td>\n",
       "      <td>12.392857</td>\n",
       "      <td>37.343112</td>\n",
       "      <td>12.107143</td>\n",
       "      <td>8.321429</td>\n",
       "      <td>5.392857</td>\n",
       "      <td>...</td>\n",
       "      <td>20.071429</td>\n",
       "      <td>64.571429</td>\n",
       "      <td>66.785714</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-15.19</td>\n",
       "      <td>-11.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>24.387097</td>\n",
       "      <td>11.870968</td>\n",
       "      <td>7.709677</td>\n",
       "      <td>11.354839</td>\n",
       "      <td>35.407908</td>\n",
       "      <td>13.548387</td>\n",
       "      <td>5.290323</td>\n",
       "      <td>3.129032</td>\n",
       "      <td>...</td>\n",
       "      <td>16.580645</td>\n",
       "      <td>68.354839</td>\n",
       "      <td>62.580645</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>8.55</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>Alabama State</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>35.938776</td>\n",
       "      <td>11.542857</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>4.657143</td>\n",
       "      <td>...</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>61.314286</td>\n",
       "      <td>63.828571</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-13.37</td>\n",
       "      <td>-10.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year           team_name      fg_pg      ft_pg  three_pt_pg     orb_pg  \\\n",
       "0  2011.0           Air Force  22.562500  13.062500     6.625000   5.843750   \n",
       "1  2011.0               Akron  24.777778  12.694444     7.861111  10.083333   \n",
       "2  2011.0         Alabama A&M  22.607143  14.892857     4.464286  12.392857   \n",
       "3  2011.0  Alabama-Birmingham  24.387097  11.870968     7.709677  11.354839   \n",
       "4  2011.0       Alabama State  20.800000  15.000000     4.714286  13.142857   \n",
       "\n",
       "      drb_pg     ast_pg    stl_pg    blk_pg  ...      pf_pg      pt_pg  \\\n",
       "0  28.504883  15.437500  6.250000  2.593750  ...  17.593750  64.812500   \n",
       "1  34.108796  14.444444  6.666667  3.583333  ...  19.222222  70.111111   \n",
       "2  37.343112  12.107143  8.321429  5.392857  ...  20.071429  64.571429   \n",
       "3  35.407908  13.548387  5.290323  3.129032  ...  16.580645  68.354839   \n",
       "4  35.938776  11.542857  7.285714  4.657143  ...  22.200000  61.314286   \n",
       "\n",
       "   opnt_pt_pg  fg_pct  three_p_pct  ft_pct  wl_pct  conf_wl_pct    srs    sos  \n",
       "0   65.062500   0.471        0.377   0.705   0.500     0.375000   2.71   3.31  \n",
       "1   65.694444   0.430        0.361   0.704   0.639     0.562500   2.15  -1.02  \n",
       "2   66.785714   0.396        0.288   0.624   0.464     0.555556 -15.19 -11.75  \n",
       "3   62.580645   0.438        0.342   0.717   0.710     0.750000   8.55   2.78  \n",
       "4   63.828571   0.395        0.283   0.603   0.486     0.611111 -13.37 -10.31  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_team.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team_1_name</th>\n",
       "      <th>team_1_score</th>\n",
       "      <th>team_1_seed</th>\n",
       "      <th>team_2_name</th>\n",
       "      <th>team_2_score</th>\n",
       "      <th>team_2_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>UTSA</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>61.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>Princeton</td>\n",
       "      <td>57.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>66.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year team_1_name  team_1_score  team_1_seed    team_2_name  team_2_score  \\\n",
       "0  2011        UTSA          46.0         16.0     Ohio State          75.0   \n",
       "1  2011   Villanova          57.0          9.0   George Mason          61.0   \n",
       "2  2011     Clemson          76.0         12.0  West Virginia          84.0   \n",
       "3  2011   Princeton          57.0         13.0       Kentucky          59.0   \n",
       "4  2011      Xavier          55.0          6.0      Marquette          66.0   \n",
       "\n",
       "   team_2_seed  \n",
       "0          1.0  \n",
       "1          8.0  \n",
       "2          5.0  \n",
       "3          4.0  \n",
       "4         11.0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_game.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps_game.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to query the dataframes for specific column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team[(df_team['year'] == 2011) & (df_team['team_name'] == \"Air Force\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get team stats for post-season games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shared\n",
    "ps_team_stats_df = shared.get_team_stats_df(df_team, df_ps_game, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_team_stats_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat the team stats with the post-season game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_game_w_team_stats = pd.concat([df_ps_game, ps_team_stats_df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_game_w_team_stats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ps_game_w_team_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check true/false ratio for team 1 win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_win_map = {True:1, False:0}\n",
    "ps_game_w_team_stats['t1_win'] = ps_game_w_team_stats['t1_win'].map(t1_win_map)\n",
    "num_true = len(ps_game_w_team_stats.loc[ps_game_w_team_stats['t1_win'] == True])\n",
    "num_false = len(ps_game_w_team_stats.loc[ps_game_w_team_stats['t1_win'] == False])\n",
    "print(\"Number of True cases: {0} ({1:2.2f}%)\".format(num_true, (num_true/(num_true+num_false))*100))\n",
    "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_false, (num_false/(num_true+num_false))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training, validation, and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "ps_predict_class_names = ['t1_win']\n",
    "ps_x = ps_game_w_team_stats[shared.ps_feature_col_names].values\n",
    "ps_y = ps_game_w_team_stats[shared.ps_predict_class_names].values\n",
    "split_test_size = 0.30\n",
    "\n",
    "ps_x_train, ps_x_test, ps_y_train, ps_y_test = sklearn.model_selection.train_test_split(ps_x, ps_y, test_size=split_test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(ps_x_train)/len(ps_game_w_team_stats.index))*100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(ps_x_test)/len(ps_game_w_team_stats.index))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imput with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.impute\n",
    "\n",
    "#Impute with mean all 0 readings\n",
    "fill_0 = sklearn.impute.SimpleImputer(missing_values=0, strategy=\"mean\")\n",
    "\n",
    "ps_x_train = fill_0.fit_transform(ps_x_train)\n",
    "ps_x_test = fill_0.fit_transform(ps_x_test)\n",
    "\n",
    "# TODO : impute incorrect negative values such anything other than (SOS and SRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Baive Bayes mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "ps_nb_model = GaussianNB()\n",
    "ps_nb_model.fit(ps_x_train, ps_y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfrormance on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ps_nb_predict_test = ps_nb_model.predict(ps_x_test)\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(ps_y_test, ps_nb_predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ps - Confusion Matrix\")\n",
    "\n",
    "print(\"{0}\".format(metrics.confusion_matrix(ps_y_test, ps_nb_predict_test, labels=[1, 0])))\n",
    "print(\"\")\n",
    "\n",
    "print(\"PS -Classification Report\")\n",
    "print(metrics.classification_report(ps_y_test, ps_nb_predict_test, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forsest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ps_rf_model = RandomForestClassifier(random_state=42)\n",
    "ps_rf_model.fit(ps_x_train, ps_y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rf_predict_test = ps_rf_model.predict(ps_x_test)\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(ps_y_test, ps_rf_predict_test))) # Will be low because of over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Setting up regularization Params\n",
    "def get_best_score_C_val_for_LR(x_tr, y_tr, x_tst, y_tst):\n",
    "    C_start = 0.1\n",
    "    C_end = 5\n",
    "    C_inc = 0.1\n",
    "    C_values, recall_scores = [], []\n",
    "    C_val = C_start\n",
    "    best_recall_score = 0\n",
    "\n",
    "    while (C_val < C_end):\n",
    "        C_values.append(C_val)\n",
    "        lr_model_loop = LogisticRegression(C=C_val, random_state=42)\n",
    "        lr_model_loop.fit(x_tr, y_tr.ravel())\n",
    "        lr_predict_loop_test = lr_model_loop.predict(x_tst)\n",
    "        recall_score = metrics.recall_score(y_tst, lr_predict_loop_test)\n",
    "        recall_scores.append(recall_score)\n",
    "        if (recall_score > best_recall_score):\n",
    "            best_recall_score = recall_score\n",
    "            best_lr_predict_test = lr_predict_loop_test\n",
    "        C_val = C_val + C_inc\n",
    "    best_score_C_val = C_values[recall_scores.index(best_recall_score)]\n",
    "    print(\"1st max valu of {0:.3f} occured at C={1:.3f}\".format(best_recall_score, best_score_C_val))\n",
    "    %matplotlib inline\n",
    "    plt.plot(C_values, recall_scores, \"-\")\n",
    "    plt.xlabel(\"C value\")\n",
    "    plt.ylabel(\"recall score\")\n",
    "    return best_score_C_val\n",
    "ps_best_score_C_val = get_best_score_C_val_for_LR(ps_x_train, ps_y_train, ps_x_test, ps_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ps_lr_model = LogisticRegression(class_weight=\"balanced\", C=ps_best_score_C_val, random_state=42)\n",
    "ps_lr_model.fit(ps_x_train, ps_y_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_lr_predict_test = ps_lr_model.predict(ps_x_test)\n",
    "print(\"Accuracy: {0:.4f}\",format(metrics.accuracy_score(ps_y_test, ps_lr_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "ps_lr_cv_model = LogisticRegressionCV(n_jobs=-1, random_state=42, Cs=3, cv=10, refit=True, class_weight=\"balanced\") #Set number of folds\n",
    "ps_lr_cv_model.fit(ps_x_train, ps_y_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_lr_cv_predict_test = ps_lr_cv_model.predict(ps_x_test)\n",
    "print(\"Accuracy: {0:.4f}\",format(metrics.accuracy_score(ps_y_test, ps_lr_cv_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have trained our models, not experiment with them to produce your bracket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup This years bracket regions\n",
    "# TODO: automate this with the data received from the scraper from https://www.sports-reference.com/cbb/postseason/2021-ncaa.html\n",
    "# Note: we are ignoring some of the play in teams since 16 seeds are not frequent upset candidates\n",
    "team_names_south = [\n",
    "    # south region\n",
    "    ('Alabama', 1),('Hartford', 16),\n",
    "    ('Maryland', 8), ('West Virginia', 9),\n",
    "    ('San Diego State',5), ('Charleston Southern', 12),\n",
    "    ('Virginia',4), ('Furman', 13),\n",
    "    ('Creighton', 6), (\"NC State\", 11),\n",
    "    ('Baylor',3), ('UC Santa Barbara',14),\n",
    "    ('Missouri',7),('Utah State',10),\n",
    "    ('Arizona',2), ('Princeton',15)\n",
    "]\n",
    "team_names_west = [\n",
    "    # west region\n",
    "    ('Kansas', 1),('Howard',16),\n",
    "    ('Arkansas',8), ('Illinois',9),\n",
    "    (\"Saint Mary's (CA)\",5), ('VCU',12),\n",
    "    ('Connecticut',4), ('Iona',13),\n",
    "    ('TCU',6), ('Arizona State',11),\n",
    "    ('Gonzaga',3), ('Grand Canyon',14),\n",
    "    ('Northwestern',7), ('Boise State',10),\n",
    "    ('UCLA', 2), (\"UNC Asheville\",15)\n",
    "\n",
    "]\n",
    "team_names_east = [\n",
    "    # east region\n",
    "    ('Purdue',1),('Texas Southern',16), \n",
    "    ('Memphis', 8),('Florida Atlantic', 9),\n",
    "    ('Duke',5), ('Oral Roberts', 12),\n",
    "    ('Tennessee',4), ('Louisiana',13),\n",
    "    ('Kentucky',6),('Providence',11), \n",
    "    ('Kansas State', 3),('Montana State', 14),\n",
    "    ('Michigan State',7),('USC',10),\n",
    "    ('Marquette',2),('Vermont',15)\n",
    "]\n",
    "team_names_midwest = [\n",
    "    # mid-west region\n",
    "    ('Houston', 1),('Northern Kentucky', 16),\n",
    "    ('Iowa', 8), ('Auburn', 9),\n",
    "    ('Miami (FL)',5), ('Drake', 12),\n",
    "    ('Indiana',4), ('Kent State', 13),\n",
    "    ('Iowa State', 6), ('Mississippi State', 11),\n",
    "    ('Xavier',3), ('Kennesaw State',14),\n",
    "    ('Texas A&M',7),('Penn State',10),\n",
    "    ('Texas',2), ('Colgate',15)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Methods to add evaluating the predicted winners of matchups and subbrackets (A region or Final Four)\n",
    "    To change the predictive model used, just change the model handed to \"evaluate_winner(teams,sub_bracket_name, model)\"\n",
    "    found later in the notebook\n",
    "'''\n",
    "def get_matchup_winners(matchup_stats, teams, model, post_season):\n",
    "    if(post_season):\n",
    "        x_tourney = matchup_stats[shared.ps_feature_col_names].values\n",
    "    else:\n",
    "        x_tourney = matchup_stats[shared.feature_col_names].values\n",
    "    y_tourney = model.predict(x_tourney)\n",
    "    i = 0\n",
    "    winners = []\n",
    "    for y_val in y_tourney:\n",
    "        t1_name, t1_seed = teams[i]\n",
    "        t2_name, t2_seed = teams[i + 1]\n",
    "        print(t1_name,t1_seed,' vs. ', t2_name,t2_seed,'(team 1 won=', y_val,')')\n",
    "        if(y_val):\n",
    "            winners.append((t1_name,t1_seed))\n",
    "        else:\n",
    "            winners.append((t2_name, t2_seed))\n",
    "        i = i + 2\n",
    "    return winners\n",
    "\n",
    "def evaluate_winner(teams,sub_bracket_name, model):\n",
    "    print('Evaluating Winner of ',sub_bracket_name)\n",
    "    remaining_teams = teams\n",
    "    i = 1\n",
    "    while(len(remaining_teams) > 1):\n",
    "        post_season_stats = True\n",
    "        print(\"---\",sub_bracket_name,\" round \",i,\"---\")\n",
    "        matchup_stats = shared.get_matchups_stats(df_team, remaining_teams, post_season_stats, 2023)\n",
    "        # TODO: the 2023 should not be a magic number\n",
    "        remaining_teams = get_matchup_winners(matchup_stats,remaining_teams, model, post_season_stats)\n",
    "        i = i + 1\n",
    "    winner = remaining_teams[0]\n",
    "    print('Winner of ',sub_bracket_name,':',winner)\n",
    "    print('=================================')\n",
    "    return winner\n",
    "\n",
    "def evaluate_tournament(model):\n",
    "    # Get predicted final four\n",
    "    final_four = [\n",
    "        evaluate_winner(team_names_east, \"East\", model),\n",
    "        evaluate_winner(team_names_west,\"West\", model),\n",
    "        evaluate_winner(team_names_south, \"South\", model), \n",
    "        evaluate_winner(team_names_midwest, \"MidWest\", model)\n",
    "    ]\n",
    "    print('================================')\n",
    "    champ = evaluate_winner(final_four, \"FinalFour\", model)\n",
    "    print('========= Bracket Winner =========')\n",
    "    print(champ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Season Trained Logistic Regression Model results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tournament(ps_lr_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Season Naive Baesean Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tournament(ps_nb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post season logistic regression with cross validation\n",
    "evaluate_tournament(ps_lr_cv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
